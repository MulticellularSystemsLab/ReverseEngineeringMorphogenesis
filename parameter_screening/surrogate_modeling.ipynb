{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spatial_efd\n",
    "import math \n",
    "import signac\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of input parameters and number of outputs in the feature \n",
    "num_samples = 150\n",
    "num_harmonics = 20\n",
    "num_input_parameter = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring signac workspace\n",
    "1. Extracts Surface Evolver parameters and corresponding EFD related shape features for the parameter screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Unable to determine project id for path 'C:\\Users\\Nilay\\Documents\\GitHub\\Tissue-Cartography\\parameter_screening'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-af4a3b5d08b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fetching project from signac workspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\signac\\contrib\\project.py\u001b[0m in \u001b[0;36mget_project\u001b[1;34m(root, search, **kwargs)\u001b[0m\n\u001b[0;32m   3039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3040\u001b[0m     \"\"\"\n\u001b[1;32m-> 3041\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mProject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\signac\\contrib\\project.py\u001b[0m in \u001b[0;36mget_project\u001b[1;34m(cls, root, search, **kwargs)\u001b[0m\n\u001b[0;32m   2274\u001b[0m             raise LookupError(\n\u001b[0;32m   2275\u001b[0m                 \"Unable to determine project id for path '{}'.\".format(\n\u001b[1;32m-> 2276\u001b[1;33m                     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2277\u001b[0m                 )\n\u001b[0;32m   2278\u001b[0m             )\n",
      "\u001b[1;31mLookupError\u001b[0m: Unable to determine project id for path 'C:\\Users\\Nilay\\Documents\\GitHub\\Tissue-Cartography\\parameter_screening'."
     ]
    }
   ],
   "source": [
    "# Fetching project from signac workspace\n",
    "project = signac.get_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This section of the code does the following tasks\n",
    "1. Creating input and output training data for building surrogate models\n",
    "2. The input data is stored in master_parameter_input array with shape [num_samples,num_parameters]\n",
    "3. The output data is stored in master_parameter_output array with shape [num samples, 4 x num_harmonics]\n",
    "4. The section additionally plots wing imaginal disc shape through reverse EFD  as a result of changes made in the parameter\n",
    "\"\"\"\n",
    "\n",
    "# Checking if data exists\n",
    "doesDataFileExist = os.path.isfile(\"master_feature_output.npy\")\n",
    "\n",
    "# Loading datafiles if they exist\n",
    "# Else fetching and preparing data from signac workspace\n",
    "if doesDataFileExist == True:\n",
    "    # Loading input parameters\n",
    "    master_parameter_input_n = np.load('master_parameter_input_n.npy', )\n",
    "    # Loading output EFD coefficients\n",
    "    master_feature_output = np.load('master_feature_output.npy', )\n",
    "else:\n",
    "    # Initializing input and output data\n",
    "    master_parameter_input = np.zeros([1, 35])\n",
    "    master_feature_output = np.zeros([1,80])\n",
    "\n",
    "    # Itearting throgh each job in workspace\n",
    "    for job in project:\n",
    "\n",
    "        isFile = os.path.isfile(job.fn(\"signac_job_document.json\"))\n",
    "        if isFile == True:\n",
    "            # Fetching input parameters from the .json file containing setpoints\n",
    "            input_param = job.statepoint()[\"parameter_model\"]\n",
    "            # Coverting array to a numpy array\n",
    "            input_param = np.array(input_param)\n",
    "            # Reshaping the array to concatenate to the master input \n",
    "            input_param_reshaped = np.reshape(input_param, (1, len(input_param)))\n",
    "            # Vertical concatenation of the job specific input parameter list to the mster input data\n",
    "            master_parameter_input = np.vstack((master_parameter_input,input_param_reshaped))\n",
    "\n",
    "            # Fetching efd coefficients from the output data in signac\n",
    "            efd_coeff = job.document.get(\"e_f_d\")\n",
    "            # Converting to numpy array\n",
    "            efd_coeff = np.array(efd_coeff)\n",
    "            # Converting efd coeff to xy data for visualization\n",
    "            xt, yt = spatial_efd.inverse_transform(efd_coeff, harmonic=20)\n",
    "            plt.plot(xt,yt,label=str(input_param[33]))\n",
    "            plt.axes().set_aspect('equal', 'datalim')\n",
    "            # Reshaping efd coeff in a shape of a row \n",
    "            efd_coeff = np.reshape(efd_coeff, (1,80))\n",
    "            # Stacking output features for creating a master output feature matrix\n",
    "            master_feature_output = np.vstack((master_feature_output,efd_coeff))\n",
    "\n",
    "\n",
    "    plt.legend(loc='upper left',ncol = 2, prop={'size': 6})      \n",
    "    plt.show()\n",
    "\n",
    "    # Deleting the first row containing zeros\n",
    "    master_feature_output = np.delete(master_feature_output, 0, 0)\n",
    "    master_parameter_input = np.delete(master_parameter_input, 0, 0)\n",
    "\n",
    "    # Renaming files for saving\n",
    "    master_feature_output = master_feature_output\n",
    "    master_parameter_input_n = master_parameter_input\n",
    "    \n",
    "    # saving files \n",
    "    np.save('master_parameter_input_n.npy', master_parameter_input_n)\n",
    "    np.save('master_feature_output.npy', master_feature_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualizing shapes\n",
    "\"\"\"\n",
    "plt.close()\n",
    "for i in range(120):\n",
    "    temp = master_feature_output[i,:]\n",
    "    temp2 = np.reshape(temp, (20,4))\n",
    "    xt, yt = spatial_efd.inverse_transform(temp2, harmonic=20)\n",
    "    plt.subplot(6,20,i+1)\n",
    "    plt.plot(xt,yt,color=\"black\")\n",
    "    plt.xticks(xt, \" \")\n",
    "    plt.xticks(yt, \" \")\n",
    "    plt.axis(\"off\")\n",
    "    #plt.axes().set_aspect('equal', 'datalim')\n",
    "    #plt.axes().set_aspect('equal', 'datalim')\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 35)\n",
      "(150, 80)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This section of code is useful when we have to merge a new data from workspace to existing datafile\n",
    "\"\"\"\n",
    "#master_parameter_input_1 = np.load('master_parameter_input_1.npy', )\n",
    "#master_feature_output_1 = np.load('master_feature_output_1.npy', )\n",
    "#master_parameter_input_2 = np.load('master_parameter_input_2.npy', )\n",
    "#master_feature_output_2 = np.load('master_feature_output_2.npy', )\n",
    "#master_parameter_input_3 = np.load('master_parameter_input_3.npy', )\n",
    "#master_feature_output_3 = np.load('master_feature_output_3.npy', )\n",
    "\n",
    "# Combining data from multiple parameter screens\n",
    "#master_parameter_input_n = np.vstack((master_parameter_input_1,master_parameter_input_2,master_parameter_input_3))\n",
    "#master_feature_output = np.vstack((master_feature_output_1,master_feature_output_2,master_feature_output_3))\n",
    "#np.save('master_parameter_input_n.npy', master_parameter_input_n)\n",
    "#np.save('master_feature_output.npy', master_feature_output)\n",
    "\n",
    "print(np.shape(master_parameter_input_n))\n",
    "print(np.shape(master_feature_output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing correlations: Input parameters to EFD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Importing seaborn library\\nimport seaborn as sns\\n# Creating a pairplot for visualizing correlation\\nsnsplot = sns.pairplot(\\n              df_input_output_merged,\\n              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\\n              y_vars = efd_labels\\n          )\\n# Saving plot to a file\\nsnsplot.savefig(\"correlation_param_efd.png\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This section is meant to describe the correlations between the input parameter space and the output EFD features describing shape\n",
    "   a) dataframes were created for the input and output data\n",
    "   b) seaborn.pairplot was used to visualize correlations between EFD coefficients and input parameters\n",
    "   c) Definition of parameters varied in LHS\n",
    "       i) param_2 - T_squamous_basal \n",
    "       ii) param_5 - T_cuboidal_basal\n",
    "       iii) param_8 - T_columnar_basal\n",
    "       iv) param_18 - k_columnar_basal\n",
    "       v) param_19 - k_columnar_apical\n",
    "       vi) param_20 - k_columnar_lateral\n",
    "       vii) param_34 - k_ecm\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Transforming input parameter data to log scale\n",
    "master_parameter_input = np.log(master_parameter_input_n)\n",
    "\n",
    "# Defining labels for the EFD coefficients\n",
    "efd_labels = [\"EFD_0\"]\n",
    "for i in range(1,4*num_harmonics):\n",
    "    label_to_append = \"EFD_\"+str(i)\n",
    "    efd_labels.append(label_to_append)\n",
    "# Creating dataframe for the output shape feature matrix\n",
    "df_output_features = pd.DataFrame(master_feature_output, columns = efd_labels)\n",
    "\n",
    "\n",
    "# Defining labels for the parameters\n",
    "parameter_labels = [\"param_1\"]\n",
    "for i in range(1,35):\n",
    "    label_to_append = \"param_\"+str(i+1)\n",
    "    parameter_labels.append(label_to_append)\n",
    "# Creatiing dataframe for the inpur parameters    \n",
    "df_input_parameters = pd.DataFrame(master_parameter_input, columns = parameter_labels)\n",
    "\n",
    "# merging in the input and output dataframes  \n",
    "df_input_output_merged = pd.concat([df_output_features, df_input_parameters], axis=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Importing seaborn library\n",
    "import seaborn as sns\n",
    "# Creating a pairplot for visualizing correlation\n",
    "snsplot = sns.pairplot(\n",
    "              df_input_output_merged,\n",
    "              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\n",
    "              y_vars = efd_labels\n",
    "          )\n",
    "# Saving plot to a file\n",
    "snsplot.savefig(\"correlation_param_efd.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing importance of EFD features on overall tissue shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilay\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This section shows the relative importance of each EFD component on final shape of organ\"\"\" \n",
    "\n",
    "# Specifying the efd coefficients whose relevance has to be estimated\n",
    "efd_number = 1\n",
    "\n",
    "# Calculating mean and standard deviation in the screen\n",
    "efd_mean = np.mean(master_feature_output,axis = 0)\n",
    "efd_standard_deviation = np.std(master_feature_output,axis = 0)\n",
    "\n",
    "# Defining perrturbation efd by adding 3 times the standard deviation along any component to mean \n",
    "efd_perturbed = efd_mean\n",
    "efd_perturbed[efd_number] = efd_perturbed[efd_number] + 3 * efd_standard_deviation[efd_number]\n",
    "\n",
    "# Ewshaping mean and perturbed EFDs so that they can be ibput to spatial EFD\n",
    "efd_mean_reshaped = np.reshape(efd_mean,(20,4))\n",
    "efd_perturbed_reshaped = np.reshape(efd_perturbed,(20,4))\n",
    "\n",
    "# Reverse EFD coefficients\n",
    "xt_mean, yt_mean = spatial_efd.inverse_transform(efd_mean_reshaped, harmonic=20)\n",
    "xt_perturbed, yt_perturbed = spatial_efd.inverse_transform(efd_perturbed_reshaped, harmonic=20)\n",
    "\n",
    "# Plotting the mean shape\n",
    "plt.plot(xt_mean,yt_mean,label='mean_shape')\n",
    "# Plotting the perturbed shape\n",
    "plt.plot(xt_perturbed,yt_perturbed,label='stdev along EFD'+str(efd_number))\n",
    "# Add legends\n",
    "plt.legend(loc='upper left',ncol = 2, prop={'size': 6}) \n",
    "# Set equal aspect ratio\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 80)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21895301 0.17323367 0.11290526 0.09812456 0.08294328 0.05576723\n",
      " 0.04099771 0.03003538]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npc_labels = [\"PC-1\", \"PC-2\", \"PC-3\", \"PC-4\", \"PC-5\", \"PC-6\", \"PC-7\", \"PC-8\"]\\ndf_output_pc = pd.DataFrame(principalComponents, columns = pc_labels)\\n\\ndf_input_output_pc_merged = pd.concat([df_output_pc, df_input_parameters], axis=1)\\n\\nimport seaborn as sns\\nsnsplot = sns.pairplot(\\n              df_input_output_pc_merged,\\n              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\\n              y_vars = pc_labels\\n          )\\n\\nsnsplot.savefig(\"correlation_param_efd_pc.png\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" A) his section of code proejects the feature space into lower dimensions using PCA\n",
    "b) Scikit learn was first used to normalize the data and then take principal components\n",
    "c) Varaince captured in the principal components is also estimated\n",
    "d) Further the section plots the correlations between KECM and different principal components\n",
    "\"\"\"\n",
    "# Importing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Storing the feature output data in x\n",
    "x = master_feature_output\n",
    "# Normalizing the data\n",
    "x = StandardScaler().fit_transform(x)\n",
    "# Defining number of components in PCA\n",
    "pca = PCA(n_components=8)\n",
    "# Using scikit learn to calculate PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "# Calculating weights\n",
    "weights = pca.components_\n",
    "print(np.shape(weights))\n",
    "plt.pcolor( weights , cmap = 'hsv' )\n",
    "plt.show()\n",
    "# Variance explained in the principal components\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "\"\"\"\n",
    "pc_labels = [\"PC-1\", \"PC-2\", \"PC-3\", \"PC-4\", \"PC-5\", \"PC-6\", \"PC-7\", \"PC-8\"]\n",
    "df_output_pc = pd.DataFrame(principalComponents, columns = pc_labels)\n",
    "\n",
    "df_input_output_pc_merged = pd.concat([df_output_pc, df_input_parameters], axis=1)\n",
    "\n",
    "import seaborn as sns\n",
    "snsplot = sns.pairplot(\n",
    "              df_input_output_pc_merged,\n",
    "              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\n",
    "              y_vars = pc_labels\n",
    "          )\n",
    "\n",
    "snsplot.savefig(\"correlation_param_efd_pc.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surrogate modeling**\n",
    "\n",
    "A)Input: Parameters varoied in LHS\n",
    "\n",
    "B) PCs of the EFD shape features\n",
    "Build individual models relating the Input parameters to the individual PCs of EFD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing librarie\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TRSAINING AND TESTING DATA FOR GPR MODEL\n",
    "    a) This section of the code prepares the training data for the GPR model.\n",
    "    b) Parameter that were varied during the LHS rae chosen as the input variables to the model.\n",
    "    c) Output training data are the PCs of the PCs of the EFD features\n",
    "    d) A split is carried out in the inut and output data to create a training and testing dataset for model\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Number of parameters in the Latin Hypercube sampling\n",
    "num_parameters_LHS = 7\n",
    "param_index = [1, 4, 7, 17, 18, 19, 33]\n",
    "split_size = 110\n",
    "pc_index_anal = 7\n",
    "# Initializing the training data\n",
    "train_x_numpy = np.zeros((num_samples, num_parameters_LHS))\n",
    "# Getting the parameter values from master_parameter_input\n",
    "for i in range(num_parameters_LHS):\n",
    "    train_x_numpy[:,i] = master_parameter_input[:,param_index[i]]\n",
    "\n",
    "# Normalizing the data around mean\n",
    "train_x_numpy = StandardScaler().fit_transform(train_x_numpy)\n",
    "\"\"\" Training data\"\"\"\n",
    "# Converting numpy array to tensor\n",
    "train_x = torch.from_numpy(train_x_numpy[:split_size,:])\n",
    "# Converting the output training data to numpy array\n",
    "# PC1\n",
    "train_y1 = torch.from_numpy(principalComponents[:split_size,pc_index_anal])\n",
    "# PC2\n",
    "train_y2 = torch.from_numpy(principalComponents[:split_size,1])\n",
    "# PC3\n",
    "train_y3 = torch.from_numpy(principalComponents[:split_size,2])\n",
    "# PC4 \n",
    "train_y4 = torch.from_numpy(principalComponents[:split_size,3])\n",
    "\n",
    "\"\"\" Testing data \"\"\"\n",
    "test_x = torch.from_numpy(train_x_numpy[split_size:num_samples,:])\n",
    "test_y1 = principalComponents[split_size:num_samples,pc_index_anal]\n",
    "test_y2 = principalComponents[split_size:num_samples,1]\n",
    "test_y3 = principalComponents[split_size:num_samples,2]\n",
    "test_y4 = principalComponents[split_size:num_samples,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This section of the code calculates the likelihood based on RBF Kernel\n",
    "    ExactGPModels are defined \n",
    "    A) Model 1: Input: Parameters, Output: PC1\n",
    "    B) Model 2: Input: Parameters, Output: PC2\n",
    "    C) Model 3: Input: Parameters, Output: PC3\n",
    "    D) Model 4: Input: Parameters, Output: PC4\n",
    "    \n",
    "    Code for GP regression derived from GpyTorch example: \n",
    "    https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html\n",
    "    \n",
    "    Arguements for RBFKernel()\n",
    "        a) ard_num_dim -- int -- Ue this if we want to have different lengthscales for different input parameters.\n",
    "        b) batch_shape -- torch.size -- use this if we want to have different lengths cales for different batches of data\n",
    "        c) active_dime -- array -- to be used if covariance has to be calculated only for certain dimensions\n",
    "        d) lengthscale_prior -- prior -- to b used if we want to have a prior for the lengthscale\n",
    "        c) lengthscale_constranint -- default ositive\n",
    "        f) eps -- minimum value for lengthscae\n",
    "        g) lengthscale --tensor-- depends on arguement a and b\n",
    "\"\"\"\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # Defining a RBF kernel\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        #defing a Matern kernel\n",
    "        # mu is the smoothness parameter\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# Defining models for GPR\n",
    "model1 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model2 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model3 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model4 = ExactGPModel(train_x, train_y1, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/1000 - Loss: 2.052   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/1000 - Loss: 2.021   lengthscale: 0.644   noise: 0.744\n",
      "Iter 3/1000 - Loss: 1.994   lengthscale: 0.608   noise: 0.798\n",
      "Iter 4/1000 - Loss: 1.973   lengthscale: 0.582   noise: 0.853\n",
      "Iter 5/1000 - Loss: 1.957   lengthscale: 0.568   noise: 0.908\n",
      "Iter 6/1000 - Loss: 1.944   lengthscale: 0.564   noise: 0.965\n",
      "Iter 7/1000 - Loss: 1.933   lengthscale: 0.569   noise: 1.021\n",
      "Iter 8/1000 - Loss: 1.926   lengthscale: 0.578   noise: 1.077\n",
      "Iter 9/1000 - Loss: 1.920   lengthscale: 0.592   noise: 1.131\n",
      "Iter 10/1000 - Loss: 1.917   lengthscale: 0.609   noise: 1.183\n",
      "Iter 11/1000 - Loss: 1.914   lengthscale: 0.628   noise: 1.233\n",
      "Iter 12/1000 - Loss: 1.913   lengthscale: 0.649   noise: 1.279\n",
      "Iter 13/1000 - Loss: 1.912   lengthscale: 0.670   noise: 1.323\n",
      "Iter 14/1000 - Loss: 1.912   lengthscale: 0.690   noise: 1.363\n",
      "Iter 15/1000 - Loss: 1.912   lengthscale: 0.709   noise: 1.400\n",
      "Iter 16/1000 - Loss: 1.913   lengthscale: 0.726   noise: 1.432\n",
      "Iter 17/1000 - Loss: 1.914   lengthscale: 0.740   noise: 1.461\n",
      "Iter 18/1000 - Loss: 1.915   lengthscale: 0.752   noise: 1.486\n",
      "Iter 19/1000 - Loss: 1.915   lengthscale: 0.762   noise: 1.506\n",
      "Iter 20/1000 - Loss: 1.916   lengthscale: 0.769   noise: 1.524\n",
      "Iter 21/1000 - Loss: 1.916   lengthscale: 0.774   noise: 1.537\n",
      "Iter 22/1000 - Loss: 1.917   lengthscale: 0.778   noise: 1.547\n",
      "Iter 23/1000 - Loss: 1.917   lengthscale: 0.780   noise: 1.554\n",
      "Iter 24/1000 - Loss: 1.917   lengthscale: 0.781   noise: 1.558\n",
      "Iter 25/1000 - Loss: 1.918   lengthscale: 0.781   noise: 1.558\n",
      "Iter 26/1000 - Loss: 1.917   lengthscale: 0.781   noise: 1.557\n",
      "Iter 27/1000 - Loss: 1.917   lengthscale: 0.781   noise: 1.552\n",
      "Iter 28/1000 - Loss: 1.917   lengthscale: 0.779   noise: 1.546\n",
      "Iter 29/1000 - Loss: 1.917   lengthscale: 0.777   noise: 1.537\n",
      "Iter 30/1000 - Loss: 1.916   lengthscale: 0.774   noise: 1.527\n",
      "Iter 31/1000 - Loss: 1.916   lengthscale: 0.770   noise: 1.515\n",
      "Iter 32/1000 - Loss: 1.915   lengthscale: 0.764   noise: 1.502\n",
      "Iter 33/1000 - Loss: 1.915   lengthscale: 0.758   noise: 1.488\n",
      "Iter 34/1000 - Loss: 1.915   lengthscale: 0.750   noise: 1.473\n",
      "Iter 35/1000 - Loss: 1.914   lengthscale: 0.742   noise: 1.458\n",
      "Iter 36/1000 - Loss: 1.914   lengthscale: 0.733   noise: 1.442\n",
      "Iter 37/1000 - Loss: 1.913   lengthscale: 0.724   noise: 1.426\n",
      "Iter 38/1000 - Loss: 1.913   lengthscale: 0.715   noise: 1.409\n",
      "Iter 39/1000 - Loss: 1.913   lengthscale: 0.707   noise: 1.394\n",
      "Iter 40/1000 - Loss: 1.912   lengthscale: 0.700   noise: 1.378\n",
      "Iter 41/1000 - Loss: 1.912   lengthscale: 0.694   noise: 1.363\n",
      "Iter 42/1000 - Loss: 1.912   lengthscale: 0.688   noise: 1.348\n",
      "Iter 43/1000 - Loss: 1.912   lengthscale: 0.684   noise: 1.335\n",
      "Iter 44/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.322\n",
      "Iter 45/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.310\n",
      "Iter 46/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.299\n",
      "Iter 47/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.289\n",
      "Iter 48/1000 - Loss: 1.912   lengthscale: 0.675   noise: 1.281\n",
      "Iter 49/1000 - Loss: 1.912   lengthscale: 0.675   noise: 1.274\n",
      "Iter 50/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.267\n",
      "Iter 51/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.263\n",
      "Iter 52/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.259\n",
      "Iter 53/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.256\n",
      "Iter 54/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.254\n",
      "Iter 55/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.254\n",
      "Iter 56/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.254\n",
      "Iter 57/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.254\n",
      "Iter 58/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.256\n",
      "Iter 59/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.258\n",
      "Iter 60/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.260\n",
      "Iter 61/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.263\n",
      "Iter 62/1000 - Loss: 1.912   lengthscale: 0.676   noise: 1.266\n",
      "Iter 63/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.269\n",
      "Iter 64/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.272\n",
      "Iter 65/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.275\n",
      "Iter 66/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.277\n",
      "Iter 67/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.280\n",
      "Iter 68/1000 - Loss: 1.912   lengthscale: 0.685   noise: 1.282\n",
      "Iter 69/1000 - Loss: 1.912   lengthscale: 0.686   noise: 1.284\n",
      "Iter 70/1000 - Loss: 1.912   lengthscale: 0.688   noise: 1.285\n",
      "Iter 71/1000 - Loss: 1.912   lengthscale: 0.689   noise: 1.286\n",
      "Iter 72/1000 - Loss: 1.912   lengthscale: 0.690   noise: 1.287\n",
      "Iter 73/1000 - Loss: 1.912   lengthscale: 0.691   noise: 1.287\n",
      "Iter 74/1000 - Loss: 1.912   lengthscale: 0.691   noise: 1.287\n",
      "Iter 75/1000 - Loss: 1.912   lengthscale: 0.691   noise: 1.286\n",
      "Iter 76/1000 - Loss: 1.912   lengthscale: 0.691   noise: 1.285\n",
      "Iter 77/1000 - Loss: 1.912   lengthscale: 0.691   noise: 1.284\n",
      "Iter 78/1000 - Loss: 1.912   lengthscale: 0.690   noise: 1.282\n",
      "Iter 79/1000 - Loss: 1.912   lengthscale: 0.689   noise: 1.280\n",
      "Iter 80/1000 - Loss: 1.912   lengthscale: 0.689   noise: 1.277\n",
      "Iter 81/1000 - Loss: 1.912   lengthscale: 0.688   noise: 1.275\n",
      "Iter 82/1000 - Loss: 1.912   lengthscale: 0.687   noise: 1.272\n",
      "Iter 83/1000 - Loss: 1.912   lengthscale: 0.687   noise: 1.269\n",
      "Iter 84/1000 - Loss: 1.912   lengthscale: 0.686   noise: 1.266\n",
      "Iter 85/1000 - Loss: 1.912   lengthscale: 0.686   noise: 1.263\n",
      "Iter 86/1000 - Loss: 1.912   lengthscale: 0.686   noise: 1.260\n",
      "Iter 87/1000 - Loss: 1.912   lengthscale: 0.685   noise: 1.257\n",
      "Iter 88/1000 - Loss: 1.912   lengthscale: 0.685   noise: 1.254\n",
      "Iter 89/1000 - Loss: 1.912   lengthscale: 0.685   noise: 1.251\n",
      "Iter 90/1000 - Loss: 1.912   lengthscale: 0.685   noise: 1.248\n",
      "Iter 91/1000 - Loss: 1.912   lengthscale: 0.684   noise: 1.245\n",
      "Iter 92/1000 - Loss: 1.912   lengthscale: 0.684   noise: 1.242\n",
      "Iter 93/1000 - Loss: 1.912   lengthscale: 0.684   noise: 1.240\n",
      "Iter 94/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.237\n",
      "Iter 95/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.235\n",
      "Iter 96/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.233\n",
      "Iter 97/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.231\n",
      "Iter 98/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.229\n",
      "Iter 99/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.227\n",
      "Iter 100/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.226\n",
      "Iter 101/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.224\n",
      "Iter 102/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.223\n",
      "Iter 103/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.221\n",
      "Iter 104/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.220\n",
      "Iter 105/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.219\n",
      "Iter 106/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.218\n",
      "Iter 107/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.216\n",
      "Iter 108/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.215\n",
      "Iter 109/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.214\n",
      "Iter 110/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.212\n",
      "Iter 111/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.211\n",
      "Iter 112/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.210\n",
      "Iter 113/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.208\n",
      "Iter 114/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.207\n",
      "Iter 115/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.205\n",
      "Iter 116/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.203\n",
      "Iter 117/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.201\n",
      "Iter 118/1000 - Loss: 1.912   lengthscale: 0.683   noise: 1.200\n",
      "Iter 119/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.198\n",
      "Iter 120/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.196\n",
      "Iter 121/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.194\n",
      "Iter 122/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.192\n",
      "Iter 123/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.190\n",
      "Iter 124/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.188\n",
      "Iter 125/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.186\n",
      "Iter 126/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.184\n",
      "Iter 127/1000 - Loss: 1.912   lengthscale: 0.682   noise: 1.181\n",
      "Iter 128/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.179\n",
      "Iter 129/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.177\n",
      "Iter 130/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.175\n",
      "Iter 131/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.173\n",
      "Iter 132/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.171\n",
      "Iter 133/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.169\n",
      "Iter 134/1000 - Loss: 1.912   lengthscale: 0.681   noise: 1.167\n",
      "Iter 135/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.165\n",
      "Iter 136/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.163\n",
      "Iter 137/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.161\n",
      "Iter 138/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.159\n",
      "Iter 139/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.157\n",
      "Iter 140/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.155\n",
      "Iter 141/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.153\n",
      "Iter 142/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.151\n",
      "Iter 143/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.149\n",
      "Iter 144/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.147\n",
      "Iter 145/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.145\n",
      "Iter 146/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.144\n",
      "Iter 147/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.142\n",
      "Iter 148/1000 - Loss: 1.912   lengthscale: 0.680   noise: 1.140\n",
      "Iter 149/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.138\n",
      "Iter 150/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.136\n",
      "Iter 151/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.134\n",
      "Iter 152/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.132\n",
      "Iter 153/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.130\n",
      "Iter 154/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.128\n",
      "Iter 155/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.126\n",
      "Iter 156/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.124\n",
      "Iter 157/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.122\n",
      "Iter 158/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.120\n",
      "Iter 159/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.118\n",
      "Iter 160/1000 - Loss: 1.912   lengthscale: 0.679   noise: 1.115\n",
      "Iter 161/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.113\n",
      "Iter 162/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.111\n",
      "Iter 163/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.109\n",
      "Iter 164/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.107\n",
      "Iter 165/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.105\n",
      "Iter 166/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.103\n",
      "Iter 167/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.101\n",
      "Iter 168/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.099\n",
      "Iter 169/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.097\n",
      "Iter 170/1000 - Loss: 1.912   lengthscale: 0.678   noise: 1.095\n",
      "Iter 171/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.092\n",
      "Iter 172/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.090\n",
      "Iter 173/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.088\n",
      "Iter 174/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.086\n",
      "Iter 175/1000 - Loss: 1.912   lengthscale: 0.677   noise: 1.084\n",
      "Iter 176/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.082\n",
      "Iter 177/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.080\n",
      "Iter 178/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.078\n",
      "Iter 179/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.076\n",
      "Iter 180/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.074\n",
      "Iter 181/1000 - Loss: 1.911   lengthscale: 0.677   noise: 1.072\n",
      "Iter 182/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.069\n",
      "Iter 183/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.067\n",
      "Iter 184/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.065\n",
      "Iter 185/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.063\n",
      "Iter 186/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.061\n",
      "Iter 187/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.059\n",
      "Iter 188/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.057\n",
      "Iter 189/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.055\n",
      "Iter 190/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.053\n",
      "Iter 191/1000 - Loss: 1.911   lengthscale: 0.676   noise: 1.051\n",
      "Iter 192/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.048\n",
      "Iter 193/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.046\n",
      "Iter 194/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.044\n",
      "Iter 195/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.042\n",
      "Iter 196/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.040\n",
      "Iter 197/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.038\n",
      "Iter 198/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.036\n",
      "Iter 199/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.033\n",
      "Iter 200/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.031\n",
      "Iter 201/1000 - Loss: 1.911   lengthscale: 0.675   noise: 1.029\n",
      "Iter 202/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.027\n",
      "Iter 203/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.025\n",
      "Iter 204/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.023\n",
      "Iter 205/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.021\n",
      "Iter 206/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.018\n",
      "Iter 207/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.016\n",
      "Iter 208/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.014\n",
      "Iter 209/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.012\n",
      "Iter 210/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.010\n",
      "Iter 211/1000 - Loss: 1.911   lengthscale: 0.674   noise: 1.008\n",
      "Iter 212/1000 - Loss: 1.911   lengthscale: 0.673   noise: 1.006\n",
      "Iter 213/1000 - Loss: 1.911   lengthscale: 0.673   noise: 1.003\n",
      "Iter 214/1000 - Loss: 1.911   lengthscale: 0.673   noise: 1.001\n",
      "Iter 215/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.999\n",
      "Iter 216/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.997\n",
      "Iter 217/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.995\n",
      "Iter 218/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.993\n",
      "Iter 219/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.991\n",
      "Iter 220/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.988\n",
      "Iter 221/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.986\n",
      "Iter 222/1000 - Loss: 1.911   lengthscale: 0.673   noise: 0.984\n",
      "Iter 223/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.982\n",
      "Iter 224/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.980\n",
      "Iter 225/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.978\n",
      "Iter 226/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.976\n",
      "Iter 227/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.973\n",
      "Iter 228/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.971\n",
      "Iter 229/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.969\n",
      "Iter 230/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.967\n",
      "Iter 231/1000 - Loss: 1.911   lengthscale: 0.672   noise: 0.965\n",
      "Iter 232/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.963\n",
      "Iter 233/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.961\n",
      "Iter 234/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.958\n",
      "Iter 235/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.956\n",
      "Iter 236/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.954\n",
      "Iter 237/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.952\n",
      "Iter 238/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.950\n",
      "Iter 239/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.948\n",
      "Iter 240/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.946\n",
      "Iter 241/1000 - Loss: 1.911   lengthscale: 0.671   noise: 0.943\n",
      "Iter 242/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.941\n",
      "Iter 243/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.939\n",
      "Iter 244/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.937\n",
      "Iter 245/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.935\n",
      "Iter 246/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.933\n",
      "Iter 247/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.931\n",
      "Iter 248/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.929\n",
      "Iter 249/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.926\n",
      "Iter 250/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.924\n",
      "Iter 251/1000 - Loss: 1.911   lengthscale: 0.670   noise: 0.922\n",
      "Iter 252/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.920\n",
      "Iter 253/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.918\n",
      "Iter 254/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.916\n",
      "Iter 255/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.914\n",
      "Iter 256/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.911\n",
      "Iter 257/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 258/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.907\n",
      "Iter 259/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.905\n",
      "Iter 260/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.903\n",
      "Iter 261/1000 - Loss: 1.911   lengthscale: 0.669   noise: 0.901\n",
      "Iter 262/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.899\n",
      "Iter 263/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.897\n",
      "Iter 264/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.895\n",
      "Iter 265/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.892\n",
      "Iter 266/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.890\n",
      "Iter 267/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.888\n",
      "Iter 268/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.886\n",
      "Iter 269/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.884\n",
      "Iter 270/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.882\n",
      "Iter 271/1000 - Loss: 1.911   lengthscale: 0.668   noise: 0.880\n",
      "Iter 272/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.878\n",
      "Iter 273/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.876\n",
      "Iter 274/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.874\n",
      "Iter 275/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.871\n",
      "Iter 276/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.869\n",
      "Iter 277/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.867\n",
      "Iter 278/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.865\n",
      "Iter 279/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.863\n",
      "Iter 280/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.861\n",
      "Iter 281/1000 - Loss: 1.911   lengthscale: 0.667   noise: 0.859\n",
      "Iter 282/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.857\n",
      "Iter 283/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.855\n",
      "Iter 284/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.853\n",
      "Iter 285/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.851\n",
      "Iter 286/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.849\n",
      "Iter 287/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.847\n",
      "Iter 288/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.844\n",
      "Iter 289/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.842\n",
      "Iter 290/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.840\n",
      "Iter 291/1000 - Loss: 1.911   lengthscale: 0.666   noise: 0.838\n",
      "Iter 292/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.836\n",
      "Iter 293/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.834\n",
      "Iter 294/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.832\n",
      "Iter 295/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.830\n",
      "Iter 296/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.828\n",
      "Iter 297/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.826\n",
      "Iter 298/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.824\n",
      "Iter 299/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.822\n",
      "Iter 300/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.820\n",
      "Iter 301/1000 - Loss: 1.911   lengthscale: 0.665   noise: 0.818\n",
      "Iter 302/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.816\n",
      "Iter 303/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.814\n",
      "Iter 304/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.812\n",
      "Iter 305/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.810\n",
      "Iter 306/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.808\n",
      "Iter 307/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.806\n",
      "Iter 308/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.804\n",
      "Iter 309/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.802\n",
      "Iter 310/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.800\n",
      "Iter 311/1000 - Loss: 1.911   lengthscale: 0.664   noise: 0.798\n",
      "Iter 312/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.796\n",
      "Iter 313/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.794\n",
      "Iter 314/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.792\n",
      "Iter 315/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.790\n",
      "Iter 316/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.788\n",
      "Iter 317/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.786\n",
      "Iter 318/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.784\n",
      "Iter 319/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.782\n",
      "Iter 320/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.780\n",
      "Iter 321/1000 - Loss: 1.911   lengthscale: 0.663   noise: 0.778\n",
      "Iter 322/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.776\n",
      "Iter 323/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.774\n",
      "Iter 324/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.772\n",
      "Iter 325/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.770\n",
      "Iter 326/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.768\n",
      "Iter 327/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.766\n",
      "Iter 328/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.764\n",
      "Iter 329/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.762\n",
      "Iter 330/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.760\n",
      "Iter 331/1000 - Loss: 1.911   lengthscale: 0.662   noise: 0.758\n",
      "Iter 332/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.756\n",
      "Iter 333/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.755\n",
      "Iter 334/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.753\n",
      "Iter 335/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.751\n",
      "Iter 336/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.749\n",
      "Iter 337/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.747\n",
      "Iter 338/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.745\n",
      "Iter 339/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.743\n",
      "Iter 340/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.741\n",
      "Iter 341/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.739\n",
      "Iter 342/1000 - Loss: 1.911   lengthscale: 0.661   noise: 0.737\n",
      "Iter 343/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.735\n",
      "Iter 344/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.734\n",
      "Iter 345/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.732\n",
      "Iter 346/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.730\n",
      "Iter 347/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.728\n",
      "Iter 348/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.726\n",
      "Iter 349/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.724\n",
      "Iter 350/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.722\n",
      "Iter 351/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.720\n",
      "Iter 352/1000 - Loss: 1.911   lengthscale: 0.660   noise: 0.719\n",
      "Iter 353/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.717\n",
      "Iter 354/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.715\n",
      "Iter 355/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.713\n",
      "Iter 356/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.711\n",
      "Iter 357/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.709\n",
      "Iter 358/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.707\n",
      "Iter 359/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.706\n",
      "Iter 360/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.704\n",
      "Iter 361/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.702\n",
      "Iter 362/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.700\n",
      "Iter 363/1000 - Loss: 1.911   lengthscale: 0.659   noise: 0.698\n",
      "Iter 364/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.697\n",
      "Iter 365/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.695\n",
      "Iter 366/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.693\n",
      "Iter 367/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.691\n",
      "Iter 368/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.689\n",
      "Iter 369/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.688\n",
      "Iter 370/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.686\n",
      "Iter 371/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.684\n",
      "Iter 372/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.682\n",
      "Iter 373/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.680\n",
      "Iter 374/1000 - Loss: 1.911   lengthscale: 0.658   noise: 0.679\n",
      "Iter 375/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.677\n",
      "Iter 376/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.675\n",
      "Iter 377/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.673\n",
      "Iter 378/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.672\n",
      "Iter 379/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.670\n",
      "Iter 380/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.668\n",
      "Iter 381/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.666\n",
      "Iter 382/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.665\n",
      "Iter 383/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.663\n",
      "Iter 384/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.661\n",
      "Iter 385/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.659\n",
      "Iter 386/1000 - Loss: 1.911   lengthscale: 0.657   noise: 0.658\n",
      "Iter 387/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.656\n",
      "Iter 388/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.654\n",
      "Iter 389/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.652\n",
      "Iter 390/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.651\n",
      "Iter 391/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.649\n",
      "Iter 392/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.647\n",
      "Iter 393/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.646\n",
      "Iter 394/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.644\n",
      "Iter 395/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.642\n",
      "Iter 396/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.640\n",
      "Iter 397/1000 - Loss: 1.911   lengthscale: 0.656   noise: 0.639\n",
      "Iter 398/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.637\n",
      "Iter 399/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.635\n",
      "Iter 400/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.634\n",
      "Iter 401/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.632\n",
      "Iter 402/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.630\n",
      "Iter 403/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.629\n",
      "Iter 404/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.627\n",
      "Iter 405/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.625\n",
      "Iter 406/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.624\n",
      "Iter 407/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.622\n",
      "Iter 408/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.621\n",
      "Iter 409/1000 - Loss: 1.911   lengthscale: 0.655   noise: 0.619\n",
      "Iter 410/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.617\n",
      "Iter 411/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.616\n",
      "Iter 412/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.614\n",
      "Iter 413/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.612\n",
      "Iter 414/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.611\n",
      "Iter 415/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.609\n",
      "Iter 416/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.608\n",
      "Iter 417/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.606\n",
      "Iter 418/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.604\n",
      "Iter 419/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.603\n",
      "Iter 420/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.601\n",
      "Iter 421/1000 - Loss: 1.911   lengthscale: 0.654   noise: 0.600\n",
      "Iter 422/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.598\n",
      "Iter 423/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.596\n",
      "Iter 424/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.595\n",
      "Iter 425/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.593\n",
      "Iter 426/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.592\n",
      "Iter 427/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.590\n",
      "Iter 428/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.589\n",
      "Iter 429/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.587\n",
      "Iter 430/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.586\n",
      "Iter 431/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.584\n",
      "Iter 432/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.582\n",
      "Iter 433/1000 - Loss: 1.911   lengthscale: 0.653   noise: 0.581\n",
      "Iter 434/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.579\n",
      "Iter 435/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.578\n",
      "Iter 436/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.576\n",
      "Iter 437/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.575\n",
      "Iter 438/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.573\n",
      "Iter 439/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.572\n",
      "Iter 440/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.570\n",
      "Iter 441/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.569\n",
      "Iter 442/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.567\n",
      "Iter 443/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.566\n",
      "Iter 444/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.564\n",
      "Iter 445/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.563\n",
      "Iter 446/1000 - Loss: 1.911   lengthscale: 0.652   noise: 0.561\n",
      "Iter 447/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.560\n",
      "Iter 448/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.558\n",
      "Iter 449/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.557\n",
      "Iter 450/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.555\n",
      "Iter 451/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.554\n",
      "Iter 452/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.552\n",
      "Iter 453/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.551\n",
      "Iter 454/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.550\n",
      "Iter 455/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.548\n",
      "Iter 456/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.547\n",
      "Iter 457/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.545\n",
      "Iter 458/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.544\n",
      "Iter 459/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.542\n",
      "Iter 460/1000 - Loss: 1.911   lengthscale: 0.651   noise: 0.541\n",
      "Iter 461/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.540\n",
      "Iter 462/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.538\n",
      "Iter 463/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.537\n",
      "Iter 464/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.535\n",
      "Iter 465/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.534\n",
      "Iter 466/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.532\n",
      "Iter 467/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.531\n",
      "Iter 468/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.530\n",
      "Iter 469/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.528\n",
      "Iter 470/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.527\n",
      "Iter 471/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.526\n",
      "Iter 472/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.524\n",
      "Iter 473/1000 - Loss: 1.911   lengthscale: 0.650   noise: 0.523\n",
      "Iter 474/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.521\n",
      "Iter 475/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.520\n",
      "Iter 476/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.519\n",
      "Iter 477/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.517\n",
      "Iter 478/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.516\n",
      "Iter 479/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.515\n",
      "Iter 480/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.513\n",
      "Iter 481/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.512\n",
      "Iter 482/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.511\n",
      "Iter 483/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.509\n",
      "Iter 484/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.508\n",
      "Iter 485/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.507\n",
      "Iter 486/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.505\n",
      "Iter 487/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.504\n",
      "Iter 488/1000 - Loss: 1.911   lengthscale: 0.649   noise: 0.503\n",
      "Iter 489/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.501\n",
      "Iter 490/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.500\n",
      "Iter 491/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.499\n",
      "Iter 492/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.497\n",
      "Iter 493/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.496\n",
      "Iter 494/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.495\n",
      "Iter 495/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.494\n",
      "Iter 496/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.492\n",
      "Iter 497/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.491\n",
      "Iter 498/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.490\n",
      "Iter 499/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.488\n",
      "Iter 500/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.487\n",
      "Iter 501/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.486\n",
      "Iter 502/1000 - Loss: 1.911   lengthscale: 0.648   noise: 0.485\n",
      "Iter 503/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.483\n",
      "Iter 504/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.482\n",
      "Iter 505/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.481\n",
      "Iter 506/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.480\n",
      "Iter 507/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.478\n",
      "Iter 508/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.477\n",
      "Iter 509/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.476\n",
      "Iter 510/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.475\n",
      "Iter 511/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.473\n",
      "Iter 512/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.472\n",
      "Iter 513/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 514/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.470\n",
      "Iter 515/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.469\n",
      "Iter 516/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.467\n",
      "Iter 517/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.466\n",
      "Iter 518/1000 - Loss: 1.911   lengthscale: 0.647   noise: 0.465\n",
      "Iter 519/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.464\n",
      "Iter 520/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.463\n",
      "Iter 521/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.461\n",
      "Iter 522/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.460\n",
      "Iter 523/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.459\n",
      "Iter 524/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.458\n",
      "Iter 525/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.457\n",
      "Iter 526/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.456\n",
      "Iter 527/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.454\n",
      "Iter 528/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.453\n",
      "Iter 529/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.452\n",
      "Iter 530/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.451\n",
      "Iter 531/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.450\n",
      "Iter 532/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.449\n",
      "Iter 533/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.447\n",
      "Iter 534/1000 - Loss: 1.911   lengthscale: 0.646   noise: 0.446\n",
      "Iter 535/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.445\n",
      "Iter 536/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.444\n",
      "Iter 537/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.443\n",
      "Iter 538/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.442\n",
      "Iter 539/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.441\n",
      "Iter 540/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.440\n",
      "Iter 541/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.438\n",
      "Iter 542/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.437\n",
      "Iter 543/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.436\n",
      "Iter 544/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.435\n",
      "Iter 545/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.434\n",
      "Iter 546/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.433\n",
      "Iter 547/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.432\n",
      "Iter 548/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.431\n",
      "Iter 549/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.430\n",
      "Iter 550/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.428\n",
      "Iter 551/1000 - Loss: 1.911   lengthscale: 0.645   noise: 0.427\n",
      "Iter 552/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.426\n",
      "Iter 553/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.425\n",
      "Iter 554/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.424\n",
      "Iter 555/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.423\n",
      "Iter 556/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.422\n",
      "Iter 557/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.421\n",
      "Iter 558/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.420\n",
      "Iter 559/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.419\n",
      "Iter 560/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.418\n",
      "Iter 561/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.417\n",
      "Iter 562/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.416\n",
      "Iter 563/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.415\n",
      "Iter 564/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.414\n",
      "Iter 565/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.413\n",
      "Iter 566/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.412\n",
      "Iter 567/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.411\n",
      "Iter 568/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.409\n",
      "Iter 569/1000 - Loss: 1.911   lengthscale: 0.644   noise: 0.408\n",
      "Iter 570/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.407\n",
      "Iter 571/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.406\n",
      "Iter 572/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.405\n",
      "Iter 573/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.404\n",
      "Iter 574/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.403\n",
      "Iter 575/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.402\n",
      "Iter 576/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.401\n",
      "Iter 577/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.400\n",
      "Iter 578/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.399\n",
      "Iter 579/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.398\n",
      "Iter 580/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.397\n",
      "Iter 581/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.396\n",
      "Iter 582/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.395\n",
      "Iter 583/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.394\n",
      "Iter 584/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.393\n",
      "Iter 585/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.393\n",
      "Iter 586/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.392\n",
      "Iter 587/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.391\n",
      "Iter 588/1000 - Loss: 1.911   lengthscale: 0.643   noise: 0.390\n",
      "Iter 589/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.389\n",
      "Iter 590/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.388\n",
      "Iter 591/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.387\n",
      "Iter 592/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.386\n",
      "Iter 593/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.385\n",
      "Iter 594/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.384\n",
      "Iter 595/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.383\n",
      "Iter 596/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.382\n",
      "Iter 597/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.381\n",
      "Iter 598/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.380\n",
      "Iter 599/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.379\n",
      "Iter 600/1000 - Loss: 1.911   lengthscale: 0.642   noise: 0.378\n",
      "Iter 601/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.377\n",
      "Iter 602/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.376\n",
      "Iter 603/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.376\n",
      "Iter 604/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.375\n",
      "Iter 605/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.374\n",
      "Iter 606/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.373\n",
      "Iter 607/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.372\n",
      "Iter 608/1000 - Loss: 1.910   lengthscale: 0.642   noise: 0.371\n",
      "Iter 609/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.370\n",
      "Iter 610/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.369\n",
      "Iter 611/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.368\n",
      "Iter 612/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.367\n",
      "Iter 613/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.367\n",
      "Iter 614/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.366\n",
      "Iter 615/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.365\n",
      "Iter 616/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.364\n",
      "Iter 617/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.363\n",
      "Iter 618/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.362\n",
      "Iter 619/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.361\n",
      "Iter 620/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.360\n",
      "Iter 621/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.359\n",
      "Iter 622/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.359\n",
      "Iter 623/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.358\n",
      "Iter 624/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.357\n",
      "Iter 625/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.356\n",
      "Iter 626/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.355\n",
      "Iter 627/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.354\n",
      "Iter 628/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.354\n",
      "Iter 629/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.353\n",
      "Iter 630/1000 - Loss: 1.910   lengthscale: 0.641   noise: 0.352\n",
      "Iter 631/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.351\n",
      "Iter 632/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.350\n",
      "Iter 633/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.349\n",
      "Iter 634/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.348\n",
      "Iter 635/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.348\n",
      "Iter 636/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.347\n",
      "Iter 637/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.346\n",
      "Iter 638/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.345\n",
      "Iter 639/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.344\n",
      "Iter 640/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.344\n",
      "Iter 641/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.343\n",
      "Iter 642/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.342\n",
      "Iter 643/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.341\n",
      "Iter 644/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.340\n",
      "Iter 645/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.339\n",
      "Iter 646/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.339\n",
      "Iter 647/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.338\n",
      "Iter 648/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.337\n",
      "Iter 649/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.336\n",
      "Iter 650/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.336\n",
      "Iter 651/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.335\n",
      "Iter 652/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.334\n",
      "Iter 653/1000 - Loss: 1.910   lengthscale: 0.640   noise: 0.333\n",
      "Iter 654/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.332\n",
      "Iter 655/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.332\n",
      "Iter 656/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.331\n",
      "Iter 657/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.330\n",
      "Iter 658/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.329\n",
      "Iter 659/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.329\n",
      "Iter 660/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.328\n",
      "Iter 661/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.327\n",
      "Iter 662/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.326\n",
      "Iter 663/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.325\n",
      "Iter 664/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.325\n",
      "Iter 665/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.324\n",
      "Iter 666/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.323\n",
      "Iter 667/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.322\n",
      "Iter 668/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.322\n",
      "Iter 669/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.321\n",
      "Iter 670/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.320\n",
      "Iter 671/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.319\n",
      "Iter 672/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.319\n",
      "Iter 673/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.318\n",
      "Iter 674/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.317\n",
      "Iter 675/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.317\n",
      "Iter 676/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.316\n",
      "Iter 677/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.315\n",
      "Iter 678/1000 - Loss: 1.910   lengthscale: 0.639   noise: 0.314\n",
      "Iter 679/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.314\n",
      "Iter 680/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.313\n",
      "Iter 681/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.312\n",
      "Iter 682/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.311\n",
      "Iter 683/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.311\n",
      "Iter 684/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.310\n",
      "Iter 685/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.309\n",
      "Iter 686/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.309\n",
      "Iter 687/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.308\n",
      "Iter 688/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.307\n",
      "Iter 689/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.307\n",
      "Iter 690/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.306\n",
      "Iter 691/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.305\n",
      "Iter 692/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.304\n",
      "Iter 693/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.304\n",
      "Iter 694/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.303\n",
      "Iter 695/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.302\n",
      "Iter 696/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.302\n",
      "Iter 697/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.301\n",
      "Iter 698/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.300\n",
      "Iter 699/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.300\n",
      "Iter 700/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.299\n",
      "Iter 701/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.298\n",
      "Iter 702/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.298\n",
      "Iter 703/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.297\n",
      "Iter 704/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.296\n",
      "Iter 705/1000 - Loss: 1.910   lengthscale: 0.638   noise: 0.296\n",
      "Iter 706/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.295\n",
      "Iter 707/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.294\n",
      "Iter 708/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.294\n",
      "Iter 709/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.293\n",
      "Iter 710/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.292\n",
      "Iter 711/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.292\n",
      "Iter 712/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.291\n",
      "Iter 713/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.290\n",
      "Iter 714/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.290\n",
      "Iter 715/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.289\n",
      "Iter 716/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.288\n",
      "Iter 717/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.288\n",
      "Iter 718/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.287\n",
      "Iter 719/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.287\n",
      "Iter 720/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.286\n",
      "Iter 721/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.285\n",
      "Iter 722/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.285\n",
      "Iter 723/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.284\n",
      "Iter 724/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.283\n",
      "Iter 725/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.283\n",
      "Iter 726/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.282\n",
      "Iter 727/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.282\n",
      "Iter 728/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.281\n",
      "Iter 729/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.280\n",
      "Iter 730/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.280\n",
      "Iter 731/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.279\n",
      "Iter 732/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.278\n",
      "Iter 733/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.278\n",
      "Iter 734/1000 - Loss: 1.910   lengthscale: 0.637   noise: 0.277\n",
      "Iter 735/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.277\n",
      "Iter 736/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.276\n",
      "Iter 737/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.275\n",
      "Iter 738/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.275\n",
      "Iter 739/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.274\n",
      "Iter 740/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.274\n",
      "Iter 741/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.273\n",
      "Iter 742/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.272\n",
      "Iter 743/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.272\n",
      "Iter 744/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.271\n",
      "Iter 745/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.271\n",
      "Iter 746/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.270\n",
      "Iter 747/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.270\n",
      "Iter 748/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.269\n",
      "Iter 749/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.268\n",
      "Iter 750/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.268\n",
      "Iter 751/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.267\n",
      "Iter 752/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.267\n",
      "Iter 753/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.266\n",
      "Iter 754/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.266\n",
      "Iter 755/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.265\n",
      "Iter 756/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.264\n",
      "Iter 757/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.264\n",
      "Iter 758/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.263\n",
      "Iter 759/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.263\n",
      "Iter 760/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.262\n",
      "Iter 761/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.262\n",
      "Iter 762/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.261\n",
      "Iter 763/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.260\n",
      "Iter 764/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.260\n",
      "Iter 765/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.259\n",
      "Iter 766/1000 - Loss: 1.910   lengthscale: 0.636   noise: 0.259\n",
      "Iter 767/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.258\n",
      "Iter 768/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.258\n",
      "Iter 769/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.257\n",
      "Iter 771/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.256\n",
      "Iter 772/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.256\n",
      "Iter 773/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.255\n",
      "Iter 774/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.254\n",
      "Iter 775/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.254\n",
      "Iter 776/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.253\n",
      "Iter 777/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.253\n",
      "Iter 778/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.252\n",
      "Iter 779/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.252\n",
      "Iter 780/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.251\n",
      "Iter 781/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.251\n",
      "Iter 782/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.250\n",
      "Iter 783/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.250\n",
      "Iter 784/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.249\n",
      "Iter 785/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.249\n",
      "Iter 786/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.248\n",
      "Iter 787/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.248\n",
      "Iter 788/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.247\n",
      "Iter 789/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.247\n",
      "Iter 790/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.246\n",
      "Iter 791/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.246\n",
      "Iter 792/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.245\n",
      "Iter 793/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.245\n",
      "Iter 794/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.244\n",
      "Iter 795/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.244\n",
      "Iter 796/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.243\n",
      "Iter 797/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.243\n",
      "Iter 798/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.242\n",
      "Iter 799/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.242\n",
      "Iter 800/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.241\n",
      "Iter 801/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.241\n",
      "Iter 802/1000 - Loss: 1.910   lengthscale: 0.635   noise: 0.240\n",
      "Iter 803/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.240\n",
      "Iter 804/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.239\n",
      "Iter 805/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.239\n",
      "Iter 806/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.238\n",
      "Iter 807/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.238\n",
      "Iter 808/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.237\n",
      "Iter 809/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.237\n",
      "Iter 810/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.236\n",
      "Iter 811/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.236\n",
      "Iter 812/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.235\n",
      "Iter 813/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.235\n",
      "Iter 814/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.234\n",
      "Iter 815/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.234\n",
      "Iter 816/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.233\n",
      "Iter 817/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.233\n",
      "Iter 818/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.232\n",
      "Iter 819/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.232\n",
      "Iter 820/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.231\n",
      "Iter 821/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.231\n",
      "Iter 822/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.230\n",
      "Iter 823/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.230\n",
      "Iter 824/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.230\n",
      "Iter 825/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.229\n",
      "Iter 826/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.229\n",
      "Iter 827/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.228\n",
      "Iter 828/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.228\n",
      "Iter 829/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.227\n",
      "Iter 830/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.227\n",
      "Iter 831/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.226\n",
      "Iter 832/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.226\n",
      "Iter 833/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.225\n",
      "Iter 834/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.225\n",
      "Iter 835/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.225\n",
      "Iter 836/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.224\n",
      "Iter 837/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.224\n",
      "Iter 838/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.223\n",
      "Iter 839/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.223\n",
      "Iter 840/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.222\n",
      "Iter 841/1000 - Loss: 1.910   lengthscale: 0.634   noise: 0.222\n",
      "Iter 842/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.221\n",
      "Iter 843/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.221\n",
      "Iter 844/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.221\n",
      "Iter 845/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.220\n",
      "Iter 846/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.220\n",
      "Iter 847/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.219\n",
      "Iter 848/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.219\n",
      "Iter 849/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.218\n",
      "Iter 850/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.218\n",
      "Iter 851/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.218\n",
      "Iter 852/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.217\n",
      "Iter 853/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.217\n",
      "Iter 854/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.216\n",
      "Iter 855/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.216\n",
      "Iter 856/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.215\n",
      "Iter 857/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.215\n",
      "Iter 858/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.215\n",
      "Iter 859/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.214\n",
      "Iter 860/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.214\n",
      "Iter 861/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.213\n",
      "Iter 862/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.213\n",
      "Iter 863/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.212\n",
      "Iter 864/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.212\n",
      "Iter 865/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.212\n",
      "Iter 866/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.211\n",
      "Iter 867/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.211\n",
      "Iter 868/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.210\n",
      "Iter 869/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.210\n",
      "Iter 870/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.210\n",
      "Iter 871/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.209\n",
      "Iter 872/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.209\n",
      "Iter 873/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.208\n",
      "Iter 874/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.208\n",
      "Iter 875/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.208\n",
      "Iter 876/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.207\n",
      "Iter 877/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.207\n",
      "Iter 878/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.206\n",
      "Iter 879/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.206\n",
      "Iter 880/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.206\n",
      "Iter 881/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.205\n",
      "Iter 882/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.205\n",
      "Iter 883/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.204\n",
      "Iter 884/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.204\n",
      "Iter 885/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.204\n",
      "Iter 886/1000 - Loss: 1.910   lengthscale: 0.633   noise: 0.203\n",
      "Iter 887/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.203\n",
      "Iter 888/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.203\n",
      "Iter 889/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.202\n",
      "Iter 890/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.202\n",
      "Iter 891/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.201\n",
      "Iter 892/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.201\n",
      "Iter 893/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.201\n",
      "Iter 894/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.200\n",
      "Iter 895/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.200\n",
      "Iter 896/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.199\n",
      "Iter 897/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.199\n",
      "Iter 898/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.199\n",
      "Iter 899/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.198\n",
      "Iter 900/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.198\n",
      "Iter 901/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.198\n",
      "Iter 902/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.197\n",
      "Iter 903/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.197\n",
      "Iter 904/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.196\n",
      "Iter 905/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.196\n",
      "Iter 906/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.196\n",
      "Iter 907/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.195\n",
      "Iter 908/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.195\n",
      "Iter 909/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.195\n",
      "Iter 910/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.194\n",
      "Iter 911/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.194\n",
      "Iter 912/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.194\n",
      "Iter 913/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.193\n",
      "Iter 914/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.193\n",
      "Iter 915/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.192\n",
      "Iter 916/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.192\n",
      "Iter 917/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.192\n",
      "Iter 918/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.191\n",
      "Iter 919/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.191\n",
      "Iter 920/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.191\n",
      "Iter 921/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.190\n",
      "Iter 922/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.190\n",
      "Iter 923/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.190\n",
      "Iter 924/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.189\n",
      "Iter 925/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.189\n",
      "Iter 926/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.189\n",
      "Iter 927/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.188\n",
      "Iter 928/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.188\n",
      "Iter 929/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.188\n",
      "Iter 930/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.187\n",
      "Iter 931/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.187\n",
      "Iter 932/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.187\n",
      "Iter 933/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.186\n",
      "Iter 934/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.186\n",
      "Iter 935/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.186\n",
      "Iter 936/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.185\n",
      "Iter 937/1000 - Loss: 1.910   lengthscale: 0.632   noise: 0.185\n",
      "Iter 938/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.185\n",
      "Iter 939/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.184\n",
      "Iter 940/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.184\n",
      "Iter 941/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.184\n",
      "Iter 942/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.183\n",
      "Iter 943/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.183\n",
      "Iter 944/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.183\n",
      "Iter 945/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.182\n",
      "Iter 946/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.182\n",
      "Iter 947/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.182\n",
      "Iter 948/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.181\n",
      "Iter 949/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.181\n",
      "Iter 950/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.181\n",
      "Iter 951/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.180\n",
      "Iter 952/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.180\n",
      "Iter 953/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.180\n",
      "Iter 954/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.179\n",
      "Iter 955/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.179\n",
      "Iter 956/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.179\n",
      "Iter 957/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.178\n",
      "Iter 958/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.178\n",
      "Iter 959/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.178\n",
      "Iter 960/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.177\n",
      "Iter 961/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.177\n",
      "Iter 962/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.177\n",
      "Iter 963/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.176\n",
      "Iter 964/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.176\n",
      "Iter 965/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.176\n",
      "Iter 966/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.175\n",
      "Iter 967/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.175\n",
      "Iter 968/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.175\n",
      "Iter 969/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.175\n",
      "Iter 970/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.174\n",
      "Iter 971/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.174\n",
      "Iter 972/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.174\n",
      "Iter 973/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.173\n",
      "Iter 974/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.173\n",
      "Iter 975/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.173\n",
      "Iter 976/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.172\n",
      "Iter 977/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.172\n",
      "Iter 978/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.172\n",
      "Iter 979/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.171\n",
      "Iter 980/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.171\n",
      "Iter 981/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.171\n",
      "Iter 982/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.171\n",
      "Iter 983/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.170\n",
      "Iter 984/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.170\n",
      "Iter 985/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.170\n",
      "Iter 986/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.169\n",
      "Iter 987/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.169\n",
      "Iter 988/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.169\n",
      "Iter 989/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.168\n",
      "Iter 990/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.168\n",
      "Iter 991/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.168\n",
      "Iter 992/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.168\n",
      "Iter 993/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.167\n",
      "Iter 994/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.167\n",
      "Iter 995/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.167\n",
      "Iter 996/1000 - Loss: 1.910   lengthscale: 0.631   noise: 0.166\n",
      "Iter 997/1000 - Loss: 1.910   lengthscale: 0.630   noise: 0.166\n",
      "Iter 998/1000 - Loss: 1.910   lengthscale: 0.630   noise: 0.166\n",
      "Iter 999/1000 - Loss: 1.910   lengthscale: 0.630   noise: 0.166\n",
      "Iter 1000/1000 - Loss: 1.910   lengthscale: 0.630   noise: 0.165\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training the GP models: \n",
    "A) GPyTorch was used to fit a GP with RBF Kernel\n",
    "B) The simplest likelihood for regression is the gpytorch.likelihoods.GaussianLikelihood.\n",
    "This assumes a homoskedastic noise model (i.e. all inputs have the same observational noise).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 1000\n",
    "\n",
    "\"\"\"\n",
    "TRAINING MODEL 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model1.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\"\"\" Add link to the place where the code has been taken from\n",
    "\"\"\"\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll1 = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model1)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer1.zero_grad()\n",
    "    # Output from model\n",
    "    output = model1(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll1(output, train_y1)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model1.covar_module.base_kernel.lengthscale.item(),\n",
    "        model1.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This section of the code makes prediction for the trained GP model on PC-1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model1.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred1 = likelihood(model1(test_x))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    # Calculating upper and lower bounds of model predictions\n",
    "    lower1, upper1 = observed_pred1.confidence_region()\n",
    "    # converting upper and lower bound prediction sto numpy array\n",
    "    lower1_numpy = lower1.numpy()\n",
    "    upper1_numpy = upper1.numpy()\n",
    "    # Claculating mean prediction\n",
    "    output_model_predictions_1 = observed_pred1.mean.numpy()\n",
    "    # fetching actual output data\n",
    "    original_output = test_y1\n",
    "\n",
    "# Calculating total error in predictions    \n",
    "error_prediction = np.subtract(upper1_numpy, lower1_numpy)\n",
    "# Plotting model predictions for PC1\n",
    "#print(np.amin(original_output))\n",
    "\n",
    "# Discretizing coordinate system for updating the parietal_plots\n",
    "x_par = np.linspace(np.amin(original_output),np.amax(original_output), num = 100)\n",
    "# Plotting the parietal line y = x\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(x_par, x_par)\n",
    "# Plotting the output predictions against known output value\n",
    "ax.plot(original_output, output_model_predictions_1, 'o', color='black')\n",
    "# Plotting the errorbars\n",
    "ax.errorbar(original_output, output_model_predictions_1,\n",
    "             yerr = error_prediction, lolims = lower1_numpy, uplims = upper1_numpy, linestyle = \"None\")\n",
    "# Labelling the axes\n",
    "#ax.fill_between(original_output, upper1_numpy, lower1_numpy, facecolor='blue', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\" True PC-8\")\n",
    "ax.set_ylabel(\" Predicted PC-8\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
