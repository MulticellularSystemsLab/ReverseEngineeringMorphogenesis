{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spatial_efd\n",
    "import math \n",
    "import signac\n",
    "import numpy as np\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining number of input parameters and number of outputs in the feature \n",
    "num_samples = 150\n",
    "num_harmonics = 20\n",
    "num_input_parameter = 35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exploring signac workspace\n",
    "1. Extracts Surface Evolver parameters and corresponding EFD related shape features for the parameter screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "Unable to determine project id for path 'C:\\Users\\Nilay\\Documents\\GitHub\\Tissue-Cartography\\parameter_screening'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-af4a3b5d08b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fetching project from signac workspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mproject\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\signac\\contrib\\project.py\u001b[0m in \u001b[0;36mget_project\u001b[1;34m(root, search, **kwargs)\u001b[0m\n\u001b[0;32m   3039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3040\u001b[0m     \"\"\"\n\u001b[1;32m-> 3041\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mProject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_project\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\signac\\contrib\\project.py\u001b[0m in \u001b[0;36mget_project\u001b[1;34m(cls, root, search, **kwargs)\u001b[0m\n\u001b[0;32m   2274\u001b[0m             raise LookupError(\n\u001b[0;32m   2275\u001b[0m                 \"Unable to determine project id for path '{}'.\".format(\n\u001b[1;32m-> 2276\u001b[1;33m                     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2277\u001b[0m                 )\n\u001b[0;32m   2278\u001b[0m             )\n",
      "\u001b[1;31mLookupError\u001b[0m: Unable to determine project id for path 'C:\\Users\\Nilay\\Documents\\GitHub\\Tissue-Cartography\\parameter_screening'."
     ]
    }
   ],
   "source": [
    "# Fetching project from signac workspace\n",
    "project = signac.get_project()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This section of the code does the following tasks\n",
    "1. Creating input and output training data for building surrogate models\n",
    "2. The input data is stored in master_parameter_input array with shape [num_samples,num_parameters]\n",
    "3. The output data is stored in master_parameter_output array with shape [num samples, 4 x num_harmonics]\n",
    "4. The section additionally plots wing imaginal disc shape through reverse EFD  as a result of changes made in the parameter\n",
    "\"\"\"\n",
    "\n",
    "# Checking if data exists\n",
    "doesDataFileExist = os.path.isfile(\"master_feature_output.npy\")\n",
    "\n",
    "# Loading datafiles if they exist\n",
    "# Else fetching and preparing data from signac workspace\n",
    "if doesDataFileExist == True:\n",
    "    # Loading input parameters\n",
    "    master_parameter_input_n = np.load('master_parameter_input_n.npy', )\n",
    "    # Loading output EFD coefficients\n",
    "    master_feature_output = np.load('master_feature_output.npy', )\n",
    "else:\n",
    "    # Initializing input and output data\n",
    "    master_parameter_input = np.zeros([1, 35])\n",
    "    master_feature_output = np.zeros([1,80])\n",
    "\n",
    "    # Itearting throgh each job in workspace\n",
    "    for job in project:\n",
    "\n",
    "        isFile = os.path.isfile(job.fn(\"signac_job_document.json\"))\n",
    "        if isFile == True:\n",
    "            # Fetching input parameters from the .json file containing setpoints\n",
    "            input_param = job.statepoint()[\"parameter_model\"]\n",
    "            # Coverting array to a numpy array\n",
    "            input_param = np.array(input_param)\n",
    "            # Reshaping the array to concatenate to the master input \n",
    "            input_param_reshaped = np.reshape(input_param, (1, len(input_param)))\n",
    "            # Vertical concatenation of the job specific input parameter list to the mster input data\n",
    "            master_parameter_input = np.vstack((master_parameter_input,input_param_reshaped))\n",
    "\n",
    "            # Fetching efd coefficients from the output data in signac\n",
    "            efd_coeff = job.document.get(\"e_f_d\")\n",
    "            # Converting to numpy array\n",
    "            efd_coeff = np.array(efd_coeff)\n",
    "            # Converting efd coeff to xy data for visualization\n",
    "            xt, yt = spatial_efd.inverse_transform(efd_coeff, harmonic=20)\n",
    "            plt.plot(xt,yt,label=str(input_param[33]))\n",
    "            plt.axes().set_aspect('equal', 'datalim')\n",
    "            # Reshaping efd coeff in a shape of a row \n",
    "            efd_coeff = np.reshape(efd_coeff, (1,80))\n",
    "            # Stacking output features for creating a master output feature matrix\n",
    "            master_feature_output = np.vstack((master_feature_output,efd_coeff))\n",
    "\n",
    "\n",
    "    plt.legend(loc='upper left',ncol = 2, prop={'size': 6})      \n",
    "    plt.show()\n",
    "\n",
    "    # Deleting the first row containing zeros\n",
    "    master_feature_output = np.delete(master_feature_output, 0, 0)\n",
    "    master_parameter_input = np.delete(master_parameter_input, 0, 0)\n",
    "\n",
    "    # Renaming files for saving\n",
    "    master_feature_output = master_feature_output\n",
    "    master_parameter_input_n = master_parameter_input\n",
    "    \n",
    "    # saving files \n",
    "    np.save('master_parameter_input_n.npy', master_parameter_input_n)\n",
    "    np.save('master_feature_output.npy', master_feature_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Visualizing shapes\n",
    "\"\"\"\n",
    "plt.close()\n",
    "for i in range(120):\n",
    "    temp = master_feature_output[i,:]\n",
    "    temp2 = np.reshape(temp, (20,4))\n",
    "    xt, yt = spatial_efd.inverse_transform(temp2, harmonic=20)\n",
    "    plt.subplot(6,20,i+1)\n",
    "    plt.plot(xt,yt,color=\"black\")\n",
    "    plt.xticks(xt, \" \")\n",
    "    plt.xticks(yt, \" \")\n",
    "    plt.axis(\"off\")\n",
    "    #plt.axes().set_aspect('equal', 'datalim')\n",
    "    #plt.axes().set_aspect('equal', 'datalim')\n",
    "    \n",
    "plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 35)\n",
      "(150, 80)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This section of code is useful when we have to merge a new data from workspace to existing datafile\n",
    "\"\"\"\n",
    "#master_parameter_input_1 = np.load('master_parameter_input_1.npy', )\n",
    "#master_feature_output_1 = np.load('master_feature_output_1.npy', )\n",
    "#master_parameter_input_2 = np.load('master_parameter_input_2.npy', )\n",
    "#master_feature_output_2 = np.load('master_feature_output_2.npy', )\n",
    "#master_parameter_input_3 = np.load('master_parameter_input_3.npy', )\n",
    "#master_feature_output_3 = np.load('master_feature_output_3.npy', )\n",
    "\n",
    "# Combining data from multiple parameter screens\n",
    "#master_parameter_input_n = np.vstack((master_parameter_input_1,master_parameter_input_2,master_parameter_input_3))\n",
    "#master_feature_output = np.vstack((master_feature_output_1,master_feature_output_2,master_feature_output_3))\n",
    "#np.save('master_parameter_input_n.npy', master_parameter_input_n)\n",
    "#np.save('master_feature_output.npy', master_feature_output)\n",
    "\n",
    "print(np.shape(master_parameter_input_n))\n",
    "print(np.shape(master_feature_output))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing correlations: Input parameters to EFD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilay\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in log\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# Importing seaborn library\\nimport seaborn as sns\\n# Creating a pairplot for visualizing correlation\\nsnsplot = sns.pairplot(\\n              df_input_output_merged,\\n              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\\n              y_vars = efd_labels\\n          )\\n# Saving plot to a file\\nsnsplot.savefig(\"correlation_param_efd.png\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This section is meant to describe the correlations between the input parameter space and the output EFD features describing shape\n",
    "   a) dataframes were created for the input and output data\n",
    "   b) seaborn.pairplot was used to visualize correlations between EFD coefficients and input parameters\n",
    "   c) Definition of parameters varied in LHS\n",
    "       i) param_2 - T_squamous_basal \n",
    "       ii) param_5 - T_cuboidal_basal\n",
    "       iii) param_8 - T_columnar_basal\n",
    "       iv) param_18 - k_columnar_basal\n",
    "       v) param_19 - k_columnar_apical\n",
    "       vi) param_20 - k_columnar_lateral\n",
    "       vii) param_34 - k_ecm\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Transforming input parameter data to log scale\n",
    "master_parameter_input = np.log(master_parameter_input_n)\n",
    "\n",
    "# Defining labels for the EFD coefficients\n",
    "efd_labels = [\"EFD_0\"]\n",
    "for i in range(1,4*num_harmonics):\n",
    "    label_to_append = \"EFD_\"+str(i)\n",
    "    efd_labels.append(label_to_append)\n",
    "# Creating dataframe for the output shape feature matrix\n",
    "df_output_features = pd.DataFrame(master_feature_output, columns = efd_labels)\n",
    "\n",
    "\n",
    "# Defining labels for the parameters\n",
    "parameter_labels = [\"param_1\"]\n",
    "for i in range(1,35):\n",
    "    label_to_append = \"param_\"+str(i+1)\n",
    "    parameter_labels.append(label_to_append)\n",
    "# Creatiing dataframe for the inpur parameters    \n",
    "df_input_parameters = pd.DataFrame(master_parameter_input, columns = parameter_labels)\n",
    "\n",
    "# merging in the input and output dataframes  \n",
    "df_input_output_merged = pd.concat([df_output_features, df_input_parameters], axis=1)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "# Importing seaborn library\n",
    "import seaborn as sns\n",
    "# Creating a pairplot for visualizing correlation\n",
    "snsplot = sns.pairplot(\n",
    "              df_input_output_merged,\n",
    "              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\n",
    "              y_vars = efd_labels\n",
    "          )\n",
    "# Saving plot to a file\n",
    "snsplot.savefig(\"correlation_param_efd.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualizing importance of EFD features on overall tissue shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nilay\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"This section shows the relative importance of each EFD component on final shape of organ\"\"\" \n",
    "\n",
    "# Specifying the efd coefficients whose relevance has to be estimated\n",
    "efd_number = 1\n",
    "\n",
    "# Calculating mean and standard deviation in the screen\n",
    "efd_mean = np.mean(master_feature_output,axis = 0)\n",
    "efd_standard_deviation = np.std(master_feature_output,axis = 0)\n",
    "\n",
    "# Defining perrturbation efd by adding 3 times the standard deviation along any component to mean \n",
    "efd_perturbed = efd_mean\n",
    "efd_perturbed[efd_number] = efd_perturbed[efd_number] + 3 * efd_standard_deviation[efd_number]\n",
    "\n",
    "# Ewshaping mean and perturbed EFDs so that they can be ibput to spatial EFD\n",
    "efd_mean_reshaped = np.reshape(efd_mean,(20,4))\n",
    "efd_perturbed_reshaped = np.reshape(efd_perturbed,(20,4))\n",
    "\n",
    "# Reverse EFD coefficients\n",
    "xt_mean, yt_mean = spatial_efd.inverse_transform(efd_mean_reshaped, harmonic=20)\n",
    "xt_perturbed, yt_perturbed = spatial_efd.inverse_transform(efd_perturbed_reshaped, harmonic=20)\n",
    "\n",
    "# Plotting the mean shape\n",
    "plt.plot(xt_mean,yt_mean,label='mean_shape')\n",
    "# Plotting the perturbed shape\n",
    "plt.plot(xt_perturbed,yt_perturbed,label='stdev along EFD'+str(efd_number))\n",
    "# Add legends\n",
    "plt.legend(loc='upper left',ncol = 2, prop={'size': 6}) \n",
    "# Set equal aspect ratio\n",
    "plt.axes().set_aspect('equal', 'datalim')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 80)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21895301 0.17323367 0.11290526 0.09812456 0.08294328 0.05576723\n",
      " 0.04099771 0.03003538]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npc_labels = [\"PC-1\", \"PC-2\", \"PC-3\", \"PC-4\", \"PC-5\", \"PC-6\", \"PC-7\", \"PC-8\"]\\ndf_output_pc = pd.DataFrame(principalComponents, columns = pc_labels)\\n\\ndf_input_output_pc_merged = pd.concat([df_output_pc, df_input_parameters], axis=1)\\n\\nimport seaborn as sns\\nsnsplot = sns.pairplot(\\n              df_input_output_pc_merged,\\n              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\\n              y_vars = pc_labels\\n          )\\n\\nsnsplot.savefig(\"correlation_param_efd_pc.png\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" A) his section of code proejects the feature space into lower dimensions using PCA\n",
    "b) Scikit learn was first used to normalize the data and then take principal components\n",
    "c) Varaince captured in the principal components is also estimated\n",
    "d) Further the section plots the correlations between KECM and different principal components\n",
    "\"\"\"\n",
    "# Importing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Storing the feature output data in x\n",
    "x = master_feature_output\n",
    "# Normalizing the data\n",
    "x = StandardScaler().fit_transform(x)\n",
    "# Defining number of components in PCA\n",
    "pca = PCA(n_components=8)\n",
    "# Using scikit learn to calculate PCs\n",
    "principalComponents = pca.fit_transform(x)\n",
    "# Calculating weights\n",
    "weights = pca.components_\n",
    "print(np.shape(weights))\n",
    "plt.pcolor( weights , cmap = 'hsv' )\n",
    "plt.show()\n",
    "# Variance explained in the principal components\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "\"\"\"\n",
    "pc_labels = [\"PC-1\", \"PC-2\", \"PC-3\", \"PC-4\", \"PC-5\", \"PC-6\", \"PC-7\", \"PC-8\"]\n",
    "df_output_pc = pd.DataFrame(principalComponents, columns = pc_labels)\n",
    "\n",
    "df_input_output_pc_merged = pd.concat([df_output_pc, df_input_parameters], axis=1)\n",
    "\n",
    "import seaborn as sns\n",
    "snsplot = sns.pairplot(\n",
    "              df_input_output_pc_merged,\n",
    "              x_vars = [\"param_2\",\"param_5\",\"param_8\",\"param_18\",\"param_19\",\"param_20\",\"param_34\"],\n",
    "              y_vars = pc_labels\n",
    "          )\n",
    "\n",
    "snsplot.savefig(\"correlation_param_efd_pc.png\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Surrogate modeling**\n",
    "\n",
    "A)Input: Parameters varoied in LHS\n",
    "\n",
    "B) PCs of the EFD shape features\n",
    "Build individual models relating the Input parameters to the individual PCs of EFD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing librarie\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TRSAINING AND TESTING DATA FOR GPR MODEL\n",
    "    a) This section of the code prepares the training data for the GPR model.\n",
    "    b) Parameter that were varied during the LHS rae chosen as the input variables to the model.\n",
    "    c) Output training data are the PCs of the PCs of the EFD features\n",
    "    d) A split is carried out in the inut and output data to create a training and testing dataset for model\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "# Number of parameters in the Latin Hypercube sampling\n",
    "num_parameters_LHS = 7\n",
    "param_index = [1, 4, 7, 17, 18, 19, 33]\n",
    "split_size = 110\n",
    "pc_index_anal = 7\n",
    "# Initializing the training data\n",
    "train_x_numpy = np.zeros((num_samples, num_parameters_LHS))\n",
    "# Getting the parameter values from master_parameter_input\n",
    "for i in range(num_parameters_LHS):\n",
    "    train_x_numpy[:,i] = master_parameter_input[:,param_index[i]]\n",
    "\n",
    "# Normalizing the data around mean\n",
    "train_x_numpy = StandardScaler().fit_transform(train_x_numpy)\n",
    "\"\"\" Training data\"\"\"\n",
    "# Converting numpy array to tensor\n",
    "train_x = torch.from_numpy(train_x_numpy[:split_size,:])\n",
    "# Converting the output training data to numpy array\n",
    "# PC1\n",
    "train_y1 = torch.from_numpy(principalComponents[:split_size,pc_index_anal])\n",
    "# PC2\n",
    "train_y2 = torch.from_numpy(principalComponents[:split_size,1])\n",
    "# PC3\n",
    "train_y3 = torch.from_numpy(principalComponents[:split_size,2])\n",
    "# PC4 \n",
    "train_y4 = torch.from_numpy(principalComponents[:split_size,3])\n",
    "\n",
    "\"\"\" Testing data \"\"\"\n",
    "test_x = torch.from_numpy(train_x_numpy[split_size:num_samples,:])\n",
    "test_y1 = principalComponents[split_size:num_samples,pc_index_anal]\n",
    "test_y2 = principalComponents[split_size:num_samples,1]\n",
    "test_y3 = principalComponents[split_size:num_samples,2]\n",
    "test_y4 = principalComponents[split_size:num_samples,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This section of the code calculates the likelihood based on RBF Kernel\n",
    "    ExactGPModels are defined \n",
    "    A) Model 1: Input: Parameters, Output: PC1\n",
    "    B) Model 2: Input: Parameters, Output: PC2\n",
    "    C) Model 3: Input: Parameters, Output: PC3\n",
    "    D) Model 4: Input: Parameters, Output: PC4\n",
    "    \n",
    "    Code for GP regression derived from GpyTorch example: \n",
    "    https://docs.gpytorch.ai/en/stable/examples/01_Exact_GPs/Simple_GP_Regression.html\n",
    "    \n",
    "    Arguements for RBFKernel()\n",
    "        a) ard_num_dim -- int -- Ue this if we want to have different lengthscales for different input parameters.\n",
    "        b) batch_shape -- torch.size -- use this if we want to have different lengths cales for different batches of data\n",
    "        c) active_dime -- array -- to be used if covariance has to be calculated only for certain dimensions\n",
    "        d) lengthscale_prior -- prior -- to b used if we want to have a prior for the lengthscale\n",
    "        c) lengthscale_constranint -- default ositive\n",
    "        f) eps -- minimum value for lengthscae\n",
    "        g) lengthscale --tensor-- depends on arguement a and b\n",
    "\"\"\"\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        # Defining a RBF kernel\n",
    "        #self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel())\n",
    "        #defing a Matern kernel\n",
    "        # mu is the smoothness parameter\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.MaternKernel(nu=0.5))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "# Defining models for GPR\n",
    "model1 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model2 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model3 = ExactGPModel(train_x, train_y1, likelihood)\n",
    "model4 = ExactGPModel(train_x, train_y1, likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1/1000 - Loss: 2.188   lengthscale: 0.693   noise: 0.693\n",
      "Iter 2/1000 - Loss: 2.146   lengthscale: 0.744   noise: 0.744\n",
      "Iter 3/1000 - Loss: 2.109   lengthscale: 0.798   noise: 0.798\n",
      "Iter 4/1000 - Loss: 2.080   lengthscale: 0.851   noise: 0.853\n",
      "Iter 5/1000 - Loss: 2.056   lengthscale: 0.902   noise: 0.909\n",
      "Iter 6/1000 - Loss: 2.036   lengthscale: 0.948   noise: 0.967\n",
      "Iter 7/1000 - Loss: 2.020   lengthscale: 0.989   noise: 1.025\n",
      "Iter 8/1000 - Loss: 2.007   lengthscale: 1.023   noise: 1.082\n",
      "Iter 9/1000 - Loss: 1.997   lengthscale: 1.050   noise: 1.140\n",
      "Iter 10/1000 - Loss: 1.990   lengthscale: 1.071   noise: 1.196\n",
      "Iter 11/1000 - Loss: 1.984   lengthscale: 1.087   noise: 1.251\n",
      "Iter 12/1000 - Loss: 1.979   lengthscale: 1.100   noise: 1.305\n",
      "Iter 13/1000 - Loss: 1.976   lengthscale: 1.111   noise: 1.356\n",
      "Iter 14/1000 - Loss: 1.974   lengthscale: 1.120   noise: 1.404\n",
      "Iter 15/1000 - Loss: 1.972   lengthscale: 1.128   noise: 1.450\n",
      "Iter 16/1000 - Loss: 1.971   lengthscale: 1.137   noise: 1.493\n",
      "Iter 17/1000 - Loss: 1.971   lengthscale: 1.147   noise: 1.533\n",
      "Iter 18/1000 - Loss: 1.971   lengthscale: 1.158   noise: 1.570\n",
      "Iter 19/1000 - Loss: 1.971   lengthscale: 1.171   noise: 1.603\n",
      "Iter 20/1000 - Loss: 1.971   lengthscale: 1.185   noise: 1.634\n",
      "Iter 21/1000 - Loss: 1.971   lengthscale: 1.202   noise: 1.661\n",
      "Iter 22/1000 - Loss: 1.972   lengthscale: 1.221   noise: 1.685\n",
      "Iter 23/1000 - Loss: 1.972   lengthscale: 1.242   noise: 1.706\n",
      "Iter 24/1000 - Loss: 1.972   lengthscale: 1.265   noise: 1.724\n",
      "Iter 25/1000 - Loss: 1.973   lengthscale: 1.290   noise: 1.740\n",
      "Iter 26/1000 - Loss: 1.973   lengthscale: 1.317   noise: 1.752\n",
      "Iter 27/1000 - Loss: 1.973   lengthscale: 1.345   noise: 1.763\n",
      "Iter 28/1000 - Loss: 1.973   lengthscale: 1.375   noise: 1.771\n",
      "Iter 29/1000 - Loss: 1.973   lengthscale: 1.405   noise: 1.776\n",
      "Iter 30/1000 - Loss: 1.973   lengthscale: 1.437   noise: 1.780\n",
      "Iter 31/1000 - Loss: 1.973   lengthscale: 1.469   noise: 1.782\n",
      "Iter 32/1000 - Loss: 1.973   lengthscale: 1.502   noise: 1.782\n",
      "Iter 33/1000 - Loss: 1.973   lengthscale: 1.534   noise: 1.781\n",
      "Iter 34/1000 - Loss: 1.973   lengthscale: 1.565   noise: 1.779\n",
      "Iter 35/1000 - Loss: 1.973   lengthscale: 1.596   noise: 1.775\n",
      "Iter 36/1000 - Loss: 1.973   lengthscale: 1.626   noise: 1.771\n",
      "Iter 37/1000 - Loss: 1.973   lengthscale: 1.654   noise: 1.766\n",
      "Iter 38/1000 - Loss: 1.973   lengthscale: 1.680   noise: 1.760\n",
      "Iter 39/1000 - Loss: 1.972   lengthscale: 1.704   noise: 1.753\n",
      "Iter 40/1000 - Loss: 1.972   lengthscale: 1.725   noise: 1.747\n",
      "Iter 41/1000 - Loss: 1.972   lengthscale: 1.743   noise: 1.740\n",
      "Iter 42/1000 - Loss: 1.972   lengthscale: 1.758   noise: 1.733\n",
      "Iter 43/1000 - Loss: 1.972   lengthscale: 1.770   noise: 1.726\n",
      "Iter 44/1000 - Loss: 1.972   lengthscale: 1.778   noise: 1.719\n",
      "Iter 45/1000 - Loss: 1.972   lengthscale: 1.783   noise: 1.712\n",
      "Iter 46/1000 - Loss: 1.972   lengthscale: 1.784   noise: 1.706\n",
      "Iter 47/1000 - Loss: 1.972   lengthscale: 1.781   noise: 1.700\n",
      "Iter 48/1000 - Loss: 1.972   lengthscale: 1.775   noise: 1.694\n",
      "Iter 49/1000 - Loss: 1.972   lengthscale: 1.765   noise: 1.688\n",
      "Iter 50/1000 - Loss: 1.972   lengthscale: 1.752   noise: 1.683\n",
      "Iter 51/1000 - Loss: 1.972   lengthscale: 1.736   noise: 1.678\n",
      "Iter 52/1000 - Loss: 1.972   lengthscale: 1.717   noise: 1.674\n",
      "Iter 53/1000 - Loss: 1.971   lengthscale: 1.696   noise: 1.669\n",
      "Iter 54/1000 - Loss: 1.971   lengthscale: 1.672   noise: 1.665\n",
      "Iter 55/1000 - Loss: 1.971   lengthscale: 1.646   noise: 1.662\n",
      "Iter 56/1000 - Loss: 1.971   lengthscale: 1.619   noise: 1.658\n",
      "Iter 57/1000 - Loss: 1.971   lengthscale: 1.590   noise: 1.655\n",
      "Iter 58/1000 - Loss: 1.971   lengthscale: 1.561   noise: 1.652\n",
      "Iter 59/1000 - Loss: 1.971   lengthscale: 1.531   noise: 1.649\n",
      "Iter 60/1000 - Loss: 1.971   lengthscale: 1.502   noise: 1.646\n",
      "Iter 61/1000 - Loss: 1.971   lengthscale: 1.472   noise: 1.643\n",
      "Iter 62/1000 - Loss: 1.971   lengthscale: 1.444   noise: 1.640\n",
      "Iter 63/1000 - Loss: 1.971   lengthscale: 1.417   noise: 1.637\n",
      "Iter 64/1000 - Loss: 1.971   lengthscale: 1.391   noise: 1.634\n",
      "Iter 65/1000 - Loss: 1.970   lengthscale: 1.367   noise: 1.630\n",
      "Iter 66/1000 - Loss: 1.970   lengthscale: 1.345   noise: 1.627\n",
      "Iter 67/1000 - Loss: 1.970   lengthscale: 1.325   noise: 1.623\n",
      "Iter 68/1000 - Loss: 1.970   lengthscale: 1.308   noise: 1.620\n",
      "Iter 69/1000 - Loss: 1.970   lengthscale: 1.293   noise: 1.616\n",
      "Iter 70/1000 - Loss: 1.970   lengthscale: 1.281   noise: 1.612\n",
      "Iter 71/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.608\n",
      "Iter 72/1000 - Loss: 1.970   lengthscale: 1.264   noise: 1.604\n",
      "Iter 73/1000 - Loss: 1.970   lengthscale: 1.259   noise: 1.601\n",
      "Iter 74/1000 - Loss: 1.970   lengthscale: 1.256   noise: 1.597\n",
      "Iter 75/1000 - Loss: 1.970   lengthscale: 1.255   noise: 1.593\n",
      "Iter 76/1000 - Loss: 1.970   lengthscale: 1.255   noise: 1.589\n",
      "Iter 77/1000 - Loss: 1.970   lengthscale: 1.257   noise: 1.586\n",
      "Iter 78/1000 - Loss: 1.970   lengthscale: 1.260   noise: 1.582\n",
      "Iter 79/1000 - Loss: 1.970   lengthscale: 1.263   noise: 1.579\n",
      "Iter 80/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.577\n",
      "Iter 81/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.574\n",
      "Iter 82/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.572\n",
      "Iter 83/1000 - Loss: 1.970   lengthscale: 1.278   noise: 1.570\n",
      "Iter 84/1000 - Loss: 1.970   lengthscale: 1.281   noise: 1.568\n",
      "Iter 85/1000 - Loss: 1.970   lengthscale: 1.284   noise: 1.567\n",
      "Iter 86/1000 - Loss: 1.970   lengthscale: 1.285   noise: 1.566\n",
      "Iter 87/1000 - Loss: 1.970   lengthscale: 1.286   noise: 1.565\n",
      "Iter 88/1000 - Loss: 1.970   lengthscale: 1.286   noise: 1.565\n",
      "Iter 89/1000 - Loss: 1.970   lengthscale: 1.286   noise: 1.565\n",
      "Iter 90/1000 - Loss: 1.970   lengthscale: 1.285   noise: 1.565\n",
      "Iter 91/1000 - Loss: 1.970   lengthscale: 1.283   noise: 1.565\n",
      "Iter 92/1000 - Loss: 1.970   lengthscale: 1.281   noise: 1.566\n",
      "Iter 93/1000 - Loss: 1.970   lengthscale: 1.279   noise: 1.566\n",
      "Iter 94/1000 - Loss: 1.970   lengthscale: 1.277   noise: 1.567\n",
      "Iter 95/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.568\n",
      "Iter 96/1000 - Loss: 1.970   lengthscale: 1.273   noise: 1.568\n",
      "Iter 97/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.569\n",
      "Iter 98/1000 - Loss: 1.970   lengthscale: 1.270   noise: 1.570\n",
      "Iter 99/1000 - Loss: 1.970   lengthscale: 1.269   noise: 1.571\n",
      "Iter 100/1000 - Loss: 1.970   lengthscale: 1.268   noise: 1.571\n",
      "Iter 101/1000 - Loss: 1.970   lengthscale: 1.269   noise: 1.572\n",
      "Iter 102/1000 - Loss: 1.970   lengthscale: 1.269   noise: 1.572\n",
      "Iter 103/1000 - Loss: 1.970   lengthscale: 1.270   noise: 1.573\n",
      "Iter 104/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.573\n",
      "Iter 105/1000 - Loss: 1.970   lengthscale: 1.273   noise: 1.573\n",
      "Iter 106/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.573\n",
      "Iter 107/1000 - Loss: 1.970   lengthscale: 1.277   noise: 1.573\n",
      "Iter 108/1000 - Loss: 1.970   lengthscale: 1.279   noise: 1.573\n",
      "Iter 109/1000 - Loss: 1.970   lengthscale: 1.282   noise: 1.573\n",
      "Iter 110/1000 - Loss: 1.970   lengthscale: 1.284   noise: 1.573\n",
      "Iter 111/1000 - Loss: 1.970   lengthscale: 1.286   noise: 1.572\n",
      "Iter 112/1000 - Loss: 1.970   lengthscale: 1.288   noise: 1.572\n",
      "Iter 113/1000 - Loss: 1.970   lengthscale: 1.289   noise: 1.572\n",
      "Iter 114/1000 - Loss: 1.970   lengthscale: 1.290   noise: 1.571\n",
      "Iter 115/1000 - Loss: 1.970   lengthscale: 1.291   noise: 1.571\n",
      "Iter 116/1000 - Loss: 1.970   lengthscale: 1.292   noise: 1.570\n",
      "Iter 117/1000 - Loss: 1.970   lengthscale: 1.292   noise: 1.570\n",
      "Iter 118/1000 - Loss: 1.970   lengthscale: 1.292   noise: 1.569\n",
      "Iter 119/1000 - Loss: 1.970   lengthscale: 1.291   noise: 1.569\n",
      "Iter 120/1000 - Loss: 1.970   lengthscale: 1.290   noise: 1.568\n",
      "Iter 121/1000 - Loss: 1.970   lengthscale: 1.289   noise: 1.568\n",
      "Iter 122/1000 - Loss: 1.970   lengthscale: 1.288   noise: 1.567\n",
      "Iter 123/1000 - Loss: 1.970   lengthscale: 1.287   noise: 1.567\n",
      "Iter 124/1000 - Loss: 1.970   lengthscale: 1.286   noise: 1.566\n",
      "Iter 125/1000 - Loss: 1.970   lengthscale: 1.284   noise: 1.566\n",
      "Iter 126/1000 - Loss: 1.970   lengthscale: 1.283   noise: 1.565\n",
      "Iter 127/1000 - Loss: 1.970   lengthscale: 1.282   noise: 1.564\n",
      "Iter 128/1000 - Loss: 1.970   lengthscale: 1.280   noise: 1.564\n",
      "Iter 129/1000 - Loss: 1.970   lengthscale: 1.279   noise: 1.563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 130/1000 - Loss: 1.970   lengthscale: 1.278   noise: 1.562\n",
      "Iter 131/1000 - Loss: 1.970   lengthscale: 1.278   noise: 1.562\n",
      "Iter 132/1000 - Loss: 1.970   lengthscale: 1.277   noise: 1.561\n",
      "Iter 133/1000 - Loss: 1.970   lengthscale: 1.276   noise: 1.560\n",
      "Iter 134/1000 - Loss: 1.970   lengthscale: 1.276   noise: 1.559\n",
      "Iter 135/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.559\n",
      "Iter 136/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.558\n",
      "Iter 137/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.557\n",
      "Iter 138/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.556\n",
      "Iter 139/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.556\n",
      "Iter 140/1000 - Loss: 1.970   lengthscale: 1.275   noise: 1.555\n",
      "Iter 141/1000 - Loss: 1.970   lengthscale: 1.274   noise: 1.554\n",
      "Iter 142/1000 - Loss: 1.970   lengthscale: 1.274   noise: 1.554\n",
      "Iter 143/1000 - Loss: 1.970   lengthscale: 1.274   noise: 1.553\n",
      "Iter 144/1000 - Loss: 1.970   lengthscale: 1.274   noise: 1.552\n",
      "Iter 145/1000 - Loss: 1.970   lengthscale: 1.273   noise: 1.552\n",
      "Iter 146/1000 - Loss: 1.970   lengthscale: 1.273   noise: 1.551\n",
      "Iter 147/1000 - Loss: 1.970   lengthscale: 1.272   noise: 1.551\n",
      "Iter 148/1000 - Loss: 1.970   lengthscale: 1.272   noise: 1.550\n",
      "Iter 149/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.549\n",
      "Iter 150/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.549\n",
      "Iter 151/1000 - Loss: 1.970   lengthscale: 1.271   noise: 1.548\n",
      "Iter 152/1000 - Loss: 1.970   lengthscale: 1.270   noise: 1.548\n",
      "Iter 153/1000 - Loss: 1.970   lengthscale: 1.270   noise: 1.547\n",
      "Iter 154/1000 - Loss: 1.970   lengthscale: 1.269   noise: 1.547\n",
      "Iter 155/1000 - Loss: 1.970   lengthscale: 1.269   noise: 1.546\n",
      "Iter 156/1000 - Loss: 1.970   lengthscale: 1.268   noise: 1.546\n",
      "Iter 157/1000 - Loss: 1.970   lengthscale: 1.268   noise: 1.545\n",
      "Iter 158/1000 - Loss: 1.970   lengthscale: 1.268   noise: 1.545\n",
      "Iter 159/1000 - Loss: 1.970   lengthscale: 1.268   noise: 1.544\n",
      "Iter 160/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.544\n",
      "Iter 161/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.543\n",
      "Iter 162/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.543\n",
      "Iter 163/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.542\n",
      "Iter 164/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.542\n",
      "Iter 165/1000 - Loss: 1.970   lengthscale: 1.267   noise: 1.541\n",
      "Iter 166/1000 - Loss: 1.970   lengthscale: 1.266   noise: 1.541\n",
      "Iter 167/1000 - Loss: 1.970   lengthscale: 1.266   noise: 1.540\n",
      "Iter 168/1000 - Loss: 1.970   lengthscale: 1.266   noise: 1.540\n",
      "Iter 169/1000 - Loss: 1.970   lengthscale: 1.266   noise: 1.539\n",
      "Iter 170/1000 - Loss: 1.970   lengthscale: 1.266   noise: 1.539\n",
      "Iter 171/1000 - Loss: 1.970   lengthscale: 1.265   noise: 1.538\n",
      "Iter 172/1000 - Loss: 1.970   lengthscale: 1.265   noise: 1.537\n",
      "Iter 173/1000 - Loss: 1.970   lengthscale: 1.265   noise: 1.537\n",
      "Iter 174/1000 - Loss: 1.970   lengthscale: 1.264   noise: 1.536\n",
      "Iter 175/1000 - Loss: 1.970   lengthscale: 1.264   noise: 1.536\n",
      "Iter 176/1000 - Loss: 1.970   lengthscale: 1.264   noise: 1.535\n",
      "Iter 177/1000 - Loss: 1.970   lengthscale: 1.263   noise: 1.535\n",
      "Iter 178/1000 - Loss: 1.970   lengthscale: 1.263   noise: 1.534\n",
      "Iter 179/1000 - Loss: 1.970   lengthscale: 1.262   noise: 1.534\n",
      "Iter 180/1000 - Loss: 1.970   lengthscale: 1.262   noise: 1.533\n",
      "Iter 181/1000 - Loss: 1.970   lengthscale: 1.262   noise: 1.532\n",
      "Iter 182/1000 - Loss: 1.970   lengthscale: 1.261   noise: 1.532\n",
      "Iter 183/1000 - Loss: 1.970   lengthscale: 1.261   noise: 1.531\n",
      "Iter 184/1000 - Loss: 1.970   lengthscale: 1.261   noise: 1.531\n",
      "Iter 185/1000 - Loss: 1.970   lengthscale: 1.260   noise: 1.530\n",
      "Iter 186/1000 - Loss: 1.970   lengthscale: 1.260   noise: 1.530\n",
      "Iter 187/1000 - Loss: 1.970   lengthscale: 1.260   noise: 1.529\n",
      "Iter 188/1000 - Loss: 1.970   lengthscale: 1.259   noise: 1.528\n",
      "Iter 189/1000 - Loss: 1.970   lengthscale: 1.259   noise: 1.528\n",
      "Iter 190/1000 - Loss: 1.970   lengthscale: 1.259   noise: 1.527\n",
      "Iter 191/1000 - Loss: 1.970   lengthscale: 1.259   noise: 1.527\n",
      "Iter 192/1000 - Loss: 1.970   lengthscale: 1.258   noise: 1.526\n",
      "Iter 193/1000 - Loss: 1.970   lengthscale: 1.258   noise: 1.526\n",
      "Iter 194/1000 - Loss: 1.970   lengthscale: 1.258   noise: 1.525\n",
      "Iter 195/1000 - Loss: 1.970   lengthscale: 1.257   noise: 1.524\n",
      "Iter 196/1000 - Loss: 1.970   lengthscale: 1.257   noise: 1.524\n",
      "Iter 197/1000 - Loss: 1.970   lengthscale: 1.257   noise: 1.523\n",
      "Iter 198/1000 - Loss: 1.970   lengthscale: 1.256   noise: 1.523\n",
      "Iter 199/1000 - Loss: 1.970   lengthscale: 1.256   noise: 1.522\n",
      "Iter 200/1000 - Loss: 1.970   lengthscale: 1.256   noise: 1.522\n",
      "Iter 201/1000 - Loss: 1.970   lengthscale: 1.255   noise: 1.521\n",
      "Iter 202/1000 - Loss: 1.970   lengthscale: 1.255   noise: 1.521\n",
      "Iter 203/1000 - Loss: 1.970   lengthscale: 1.255   noise: 1.520\n",
      "Iter 204/1000 - Loss: 1.970   lengthscale: 1.254   noise: 1.519\n",
      "Iter 205/1000 - Loss: 1.970   lengthscale: 1.254   noise: 1.519\n",
      "Iter 206/1000 - Loss: 1.970   lengthscale: 1.254   noise: 1.518\n",
      "Iter 207/1000 - Loss: 1.970   lengthscale: 1.253   noise: 1.518\n",
      "Iter 208/1000 - Loss: 1.970   lengthscale: 1.253   noise: 1.517\n",
      "Iter 209/1000 - Loss: 1.970   lengthscale: 1.253   noise: 1.517\n",
      "Iter 210/1000 - Loss: 1.970   lengthscale: 1.253   noise: 1.516\n",
      "Iter 211/1000 - Loss: 1.970   lengthscale: 1.252   noise: 1.516\n",
      "Iter 212/1000 - Loss: 1.970   lengthscale: 1.252   noise: 1.515\n",
      "Iter 213/1000 - Loss: 1.970   lengthscale: 1.252   noise: 1.514\n",
      "Iter 214/1000 - Loss: 1.970   lengthscale: 1.251   noise: 1.514\n",
      "Iter 215/1000 - Loss: 1.970   lengthscale: 1.251   noise: 1.513\n",
      "Iter 216/1000 - Loss: 1.970   lengthscale: 1.251   noise: 1.513\n",
      "Iter 217/1000 - Loss: 1.970   lengthscale: 1.250   noise: 1.512\n",
      "Iter 218/1000 - Loss: 1.970   lengthscale: 1.250   noise: 1.512\n",
      "Iter 219/1000 - Loss: 1.970   lengthscale: 1.250   noise: 1.511\n",
      "Iter 220/1000 - Loss: 1.970   lengthscale: 1.250   noise: 1.511\n",
      "Iter 221/1000 - Loss: 1.970   lengthscale: 1.249   noise: 1.510\n",
      "Iter 222/1000 - Loss: 1.970   lengthscale: 1.249   noise: 1.510\n",
      "Iter 223/1000 - Loss: 1.970   lengthscale: 1.249   noise: 1.509\n",
      "Iter 224/1000 - Loss: 1.970   lengthscale: 1.248   noise: 1.508\n",
      "Iter 225/1000 - Loss: 1.970   lengthscale: 1.248   noise: 1.508\n",
      "Iter 226/1000 - Loss: 1.970   lengthscale: 1.248   noise: 1.507\n",
      "Iter 227/1000 - Loss: 1.970   lengthscale: 1.247   noise: 1.507\n",
      "Iter 228/1000 - Loss: 1.970   lengthscale: 1.247   noise: 1.506\n",
      "Iter 229/1000 - Loss: 1.970   lengthscale: 1.247   noise: 1.506\n",
      "Iter 230/1000 - Loss: 1.970   lengthscale: 1.247   noise: 1.505\n",
      "Iter 231/1000 - Loss: 1.970   lengthscale: 1.246   noise: 1.505\n",
      "Iter 232/1000 - Loss: 1.970   lengthscale: 1.246   noise: 1.504\n",
      "Iter 233/1000 - Loss: 1.970   lengthscale: 1.246   noise: 1.504\n",
      "Iter 234/1000 - Loss: 1.970   lengthscale: 1.245   noise: 1.503\n",
      "Iter 235/1000 - Loss: 1.970   lengthscale: 1.245   noise: 1.502\n",
      "Iter 236/1000 - Loss: 1.970   lengthscale: 1.245   noise: 1.502\n",
      "Iter 237/1000 - Loss: 1.970   lengthscale: 1.245   noise: 1.501\n",
      "Iter 238/1000 - Loss: 1.970   lengthscale: 1.244   noise: 1.501\n",
      "Iter 239/1000 - Loss: 1.970   lengthscale: 1.244   noise: 1.500\n",
      "Iter 240/1000 - Loss: 1.970   lengthscale: 1.244   noise: 1.500\n",
      "Iter 241/1000 - Loss: 1.970   lengthscale: 1.243   noise: 1.499\n",
      "Iter 242/1000 - Loss: 1.970   lengthscale: 1.243   noise: 1.499\n",
      "Iter 243/1000 - Loss: 1.970   lengthscale: 1.243   noise: 1.498\n",
      "Iter 244/1000 - Loss: 1.970   lengthscale: 1.242   noise: 1.498\n",
      "Iter 245/1000 - Loss: 1.970   lengthscale: 1.242   noise: 1.497\n",
      "Iter 246/1000 - Loss: 1.970   lengthscale: 1.242   noise: 1.497\n",
      "Iter 247/1000 - Loss: 1.970   lengthscale: 1.242   noise: 1.496\n",
      "Iter 248/1000 - Loss: 1.970   lengthscale: 1.241   noise: 1.495\n",
      "Iter 249/1000 - Loss: 1.970   lengthscale: 1.241   noise: 1.495\n",
      "Iter 250/1000 - Loss: 1.970   lengthscale: 1.241   noise: 1.494\n",
      "Iter 251/1000 - Loss: 1.970   lengthscale: 1.240   noise: 1.494\n",
      "Iter 252/1000 - Loss: 1.970   lengthscale: 1.240   noise: 1.493\n",
      "Iter 253/1000 - Loss: 1.970   lengthscale: 1.240   noise: 1.493\n",
      "Iter 254/1000 - Loss: 1.970   lengthscale: 1.240   noise: 1.492\n",
      "Iter 255/1000 - Loss: 1.970   lengthscale: 1.239   noise: 1.492\n",
      "Iter 256/1000 - Loss: 1.970   lengthscale: 1.239   noise: 1.491\n",
      "Iter 257/1000 - Loss: 1.970   lengthscale: 1.239   noise: 1.491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 258/1000 - Loss: 1.970   lengthscale: 1.238   noise: 1.490\n",
      "Iter 259/1000 - Loss: 1.970   lengthscale: 1.238   noise: 1.490\n",
      "Iter 260/1000 - Loss: 1.970   lengthscale: 1.238   noise: 1.489\n",
      "Iter 261/1000 - Loss: 1.970   lengthscale: 1.238   noise: 1.489\n",
      "Iter 262/1000 - Loss: 1.970   lengthscale: 1.237   noise: 1.488\n",
      "Iter 263/1000 - Loss: 1.970   lengthscale: 1.237   noise: 1.488\n",
      "Iter 264/1000 - Loss: 1.970   lengthscale: 1.237   noise: 1.487\n",
      "Iter 265/1000 - Loss: 1.970   lengthscale: 1.237   noise: 1.487\n",
      "Iter 266/1000 - Loss: 1.970   lengthscale: 1.236   noise: 1.486\n",
      "Iter 267/1000 - Loss: 1.970   lengthscale: 1.236   noise: 1.486\n",
      "Iter 268/1000 - Loss: 1.970   lengthscale: 1.236   noise: 1.485\n",
      "Iter 269/1000 - Loss: 1.970   lengthscale: 1.235   noise: 1.484\n",
      "Iter 270/1000 - Loss: 1.970   lengthscale: 1.235   noise: 1.484\n",
      "Iter 271/1000 - Loss: 1.970   lengthscale: 1.235   noise: 1.483\n",
      "Iter 272/1000 - Loss: 1.970   lengthscale: 1.235   noise: 1.483\n",
      "Iter 273/1000 - Loss: 1.970   lengthscale: 1.234   noise: 1.482\n",
      "Iter 274/1000 - Loss: 1.970   lengthscale: 1.234   noise: 1.482\n",
      "Iter 275/1000 - Loss: 1.970   lengthscale: 1.234   noise: 1.481\n",
      "Iter 276/1000 - Loss: 1.970   lengthscale: 1.233   noise: 1.481\n",
      "Iter 277/1000 - Loss: 1.970   lengthscale: 1.233   noise: 1.480\n",
      "Iter 278/1000 - Loss: 1.970   lengthscale: 1.233   noise: 1.480\n",
      "Iter 279/1000 - Loss: 1.970   lengthscale: 1.233   noise: 1.479\n",
      "Iter 280/1000 - Loss: 1.970   lengthscale: 1.232   noise: 1.479\n",
      "Iter 281/1000 - Loss: 1.970   lengthscale: 1.232   noise: 1.478\n",
      "Iter 282/1000 - Loss: 1.970   lengthscale: 1.232   noise: 1.478\n",
      "Iter 283/1000 - Loss: 1.970   lengthscale: 1.232   noise: 1.477\n",
      "Iter 284/1000 - Loss: 1.970   lengthscale: 1.231   noise: 1.477\n",
      "Iter 285/1000 - Loss: 1.970   lengthscale: 1.231   noise: 1.476\n",
      "Iter 286/1000 - Loss: 1.970   lengthscale: 1.231   noise: 1.476\n",
      "Iter 287/1000 - Loss: 1.970   lengthscale: 1.231   noise: 1.475\n",
      "Iter 288/1000 - Loss: 1.970   lengthscale: 1.230   noise: 1.475\n",
      "Iter 289/1000 - Loss: 1.970   lengthscale: 1.230   noise: 1.474\n",
      "Iter 290/1000 - Loss: 1.970   lengthscale: 1.230   noise: 1.474\n",
      "Iter 291/1000 - Loss: 1.970   lengthscale: 1.229   noise: 1.473\n",
      "Iter 292/1000 - Loss: 1.970   lengthscale: 1.229   noise: 1.473\n",
      "Iter 293/1000 - Loss: 1.970   lengthscale: 1.229   noise: 1.472\n",
      "Iter 294/1000 - Loss: 1.970   lengthscale: 1.229   noise: 1.472\n",
      "Iter 295/1000 - Loss: 1.970   lengthscale: 1.228   noise: 1.471\n",
      "Iter 296/1000 - Loss: 1.970   lengthscale: 1.228   noise: 1.471\n",
      "Iter 297/1000 - Loss: 1.970   lengthscale: 1.228   noise: 1.470\n",
      "Iter 298/1000 - Loss: 1.970   lengthscale: 1.228   noise: 1.470\n",
      "Iter 299/1000 - Loss: 1.970   lengthscale: 1.227   noise: 1.469\n",
      "Iter 300/1000 - Loss: 1.970   lengthscale: 1.227   noise: 1.469\n",
      "Iter 301/1000 - Loss: 1.970   lengthscale: 1.227   noise: 1.468\n",
      "Iter 302/1000 - Loss: 1.970   lengthscale: 1.227   noise: 1.468\n",
      "Iter 303/1000 - Loss: 1.970   lengthscale: 1.226   noise: 1.467\n",
      "Iter 304/1000 - Loss: 1.970   lengthscale: 1.226   noise: 1.467\n",
      "Iter 305/1000 - Loss: 1.970   lengthscale: 1.226   noise: 1.466\n",
      "Iter 306/1000 - Loss: 1.970   lengthscale: 1.226   noise: 1.466\n",
      "Iter 307/1000 - Loss: 1.970   lengthscale: 1.225   noise: 1.465\n",
      "Iter 308/1000 - Loss: 1.970   lengthscale: 1.225   noise: 1.465\n",
      "Iter 309/1000 - Loss: 1.970   lengthscale: 1.225   noise: 1.465\n",
      "Iter 310/1000 - Loss: 1.970   lengthscale: 1.225   noise: 1.464\n",
      "Iter 311/1000 - Loss: 1.970   lengthscale: 1.224   noise: 1.464\n",
      "Iter 312/1000 - Loss: 1.970   lengthscale: 1.224   noise: 1.463\n",
      "Iter 313/1000 - Loss: 1.970   lengthscale: 1.224   noise: 1.463\n",
      "Iter 314/1000 - Loss: 1.970   lengthscale: 1.224   noise: 1.462\n",
      "Iter 315/1000 - Loss: 1.970   lengthscale: 1.223   noise: 1.462\n",
      "Iter 316/1000 - Loss: 1.970   lengthscale: 1.223   noise: 1.461\n",
      "Iter 317/1000 - Loss: 1.970   lengthscale: 1.223   noise: 1.461\n",
      "Iter 318/1000 - Loss: 1.970   lengthscale: 1.223   noise: 1.460\n",
      "Iter 319/1000 - Loss: 1.970   lengthscale: 1.222   noise: 1.460\n",
      "Iter 320/1000 - Loss: 1.970   lengthscale: 1.222   noise: 1.459\n",
      "Iter 321/1000 - Loss: 1.970   lengthscale: 1.222   noise: 1.459\n",
      "Iter 322/1000 - Loss: 1.970   lengthscale: 1.222   noise: 1.458\n",
      "Iter 323/1000 - Loss: 1.970   lengthscale: 1.221   noise: 1.458\n",
      "Iter 324/1000 - Loss: 1.970   lengthscale: 1.221   noise: 1.457\n",
      "Iter 325/1000 - Loss: 1.970   lengthscale: 1.221   noise: 1.457\n",
      "Iter 326/1000 - Loss: 1.970   lengthscale: 1.221   noise: 1.456\n",
      "Iter 327/1000 - Loss: 1.970   lengthscale: 1.220   noise: 1.456\n",
      "Iter 328/1000 - Loss: 1.970   lengthscale: 1.220   noise: 1.456\n",
      "Iter 329/1000 - Loss: 1.970   lengthscale: 1.220   noise: 1.455\n",
      "Iter 330/1000 - Loss: 1.970   lengthscale: 1.220   noise: 1.455\n",
      "Iter 331/1000 - Loss: 1.970   lengthscale: 1.219   noise: 1.454\n",
      "Iter 332/1000 - Loss: 1.970   lengthscale: 1.219   noise: 1.454\n",
      "Iter 333/1000 - Loss: 1.970   lengthscale: 1.219   noise: 1.453\n",
      "Iter 334/1000 - Loss: 1.970   lengthscale: 1.219   noise: 1.453\n",
      "Iter 335/1000 - Loss: 1.970   lengthscale: 1.219   noise: 1.452\n",
      "Iter 336/1000 - Loss: 1.970   lengthscale: 1.218   noise: 1.452\n",
      "Iter 337/1000 - Loss: 1.970   lengthscale: 1.218   noise: 1.451\n",
      "Iter 338/1000 - Loss: 1.970   lengthscale: 1.218   noise: 1.451\n",
      "Iter 339/1000 - Loss: 1.970   lengthscale: 1.218   noise: 1.450\n",
      "Iter 340/1000 - Loss: 1.970   lengthscale: 1.217   noise: 1.450\n",
      "Iter 341/1000 - Loss: 1.970   lengthscale: 1.217   noise: 1.450\n",
      "Iter 342/1000 - Loss: 1.970   lengthscale: 1.217   noise: 1.449\n",
      "Iter 343/1000 - Loss: 1.970   lengthscale: 1.217   noise: 1.449\n",
      "Iter 344/1000 - Loss: 1.970   lengthscale: 1.216   noise: 1.448\n",
      "Iter 345/1000 - Loss: 1.970   lengthscale: 1.216   noise: 1.448\n",
      "Iter 346/1000 - Loss: 1.970   lengthscale: 1.216   noise: 1.447\n",
      "Iter 347/1000 - Loss: 1.970   lengthscale: 1.216   noise: 1.447\n",
      "Iter 348/1000 - Loss: 1.970   lengthscale: 1.216   noise: 1.446\n",
      "Iter 349/1000 - Loss: 1.970   lengthscale: 1.215   noise: 1.446\n",
      "Iter 350/1000 - Loss: 1.970   lengthscale: 1.215   noise: 1.446\n",
      "Iter 351/1000 - Loss: 1.970   lengthscale: 1.215   noise: 1.445\n",
      "Iter 352/1000 - Loss: 1.970   lengthscale: 1.215   noise: 1.445\n",
      "Iter 353/1000 - Loss: 1.970   lengthscale: 1.214   noise: 1.444\n",
      "Iter 354/1000 - Loss: 1.970   lengthscale: 1.214   noise: 1.444\n",
      "Iter 355/1000 - Loss: 1.970   lengthscale: 1.214   noise: 1.443\n",
      "Iter 356/1000 - Loss: 1.970   lengthscale: 1.214   noise: 1.443\n",
      "Iter 357/1000 - Loss: 1.970   lengthscale: 1.214   noise: 1.442\n",
      "Iter 358/1000 - Loss: 1.970   lengthscale: 1.213   noise: 1.442\n",
      "Iter 359/1000 - Loss: 1.970   lengthscale: 1.213   noise: 1.442\n",
      "Iter 360/1000 - Loss: 1.970   lengthscale: 1.213   noise: 1.441\n",
      "Iter 361/1000 - Loss: 1.970   lengthscale: 1.213   noise: 1.441\n",
      "Iter 362/1000 - Loss: 1.970   lengthscale: 1.212   noise: 1.440\n",
      "Iter 363/1000 - Loss: 1.970   lengthscale: 1.212   noise: 1.440\n",
      "Iter 364/1000 - Loss: 1.970   lengthscale: 1.212   noise: 1.439\n",
      "Iter 365/1000 - Loss: 1.970   lengthscale: 1.212   noise: 1.439\n",
      "Iter 366/1000 - Loss: 1.970   lengthscale: 1.212   noise: 1.439\n",
      "Iter 367/1000 - Loss: 1.970   lengthscale: 1.211   noise: 1.438\n",
      "Iter 368/1000 - Loss: 1.970   lengthscale: 1.211   noise: 1.438\n",
      "Iter 369/1000 - Loss: 1.970   lengthscale: 1.211   noise: 1.437\n",
      "Iter 370/1000 - Loss: 1.970   lengthscale: 1.211   noise: 1.437\n",
      "Iter 371/1000 - Loss: 1.970   lengthscale: 1.210   noise: 1.436\n",
      "Iter 372/1000 - Loss: 1.970   lengthscale: 1.210   noise: 1.436\n",
      "Iter 373/1000 - Loss: 1.970   lengthscale: 1.210   noise: 1.436\n",
      "Iter 374/1000 - Loss: 1.970   lengthscale: 1.210   noise: 1.435\n",
      "Iter 375/1000 - Loss: 1.970   lengthscale: 1.210   noise: 1.435\n",
      "Iter 376/1000 - Loss: 1.970   lengthscale: 1.209   noise: 1.434\n",
      "Iter 377/1000 - Loss: 1.970   lengthscale: 1.209   noise: 1.434\n",
      "Iter 378/1000 - Loss: 1.970   lengthscale: 1.209   noise: 1.434\n",
      "Iter 379/1000 - Loss: 1.970   lengthscale: 1.209   noise: 1.433\n",
      "Iter 380/1000 - Loss: 1.970   lengthscale: 1.209   noise: 1.433\n",
      "Iter 381/1000 - Loss: 1.970   lengthscale: 1.208   noise: 1.432\n",
      "Iter 382/1000 - Loss: 1.970   lengthscale: 1.208   noise: 1.432\n",
      "Iter 383/1000 - Loss: 1.970   lengthscale: 1.208   noise: 1.431\n",
      "Iter 384/1000 - Loss: 1.970   lengthscale: 1.208   noise: 1.431\n",
      "Iter 385/1000 - Loss: 1.970   lengthscale: 1.208   noise: 1.431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 386/1000 - Loss: 1.970   lengthscale: 1.207   noise: 1.430\n",
      "Iter 387/1000 - Loss: 1.970   lengthscale: 1.207   noise: 1.430\n",
      "Iter 388/1000 - Loss: 1.970   lengthscale: 1.207   noise: 1.429\n",
      "Iter 389/1000 - Loss: 1.970   lengthscale: 1.207   noise: 1.429\n",
      "Iter 390/1000 - Loss: 1.970   lengthscale: 1.207   noise: 1.429\n",
      "Iter 391/1000 - Loss: 1.970   lengthscale: 1.206   noise: 1.428\n",
      "Iter 392/1000 - Loss: 1.970   lengthscale: 1.206   noise: 1.428\n",
      "Iter 393/1000 - Loss: 1.970   lengthscale: 1.206   noise: 1.427\n",
      "Iter 394/1000 - Loss: 1.970   lengthscale: 1.206   noise: 1.427\n",
      "Iter 395/1000 - Loss: 1.970   lengthscale: 1.206   noise: 1.427\n",
      "Iter 396/1000 - Loss: 1.970   lengthscale: 1.205   noise: 1.426\n",
      "Iter 397/1000 - Loss: 1.970   lengthscale: 1.205   noise: 1.426\n",
      "Iter 398/1000 - Loss: 1.970   lengthscale: 1.205   noise: 1.425\n",
      "Iter 399/1000 - Loss: 1.970   lengthscale: 1.205   noise: 1.425\n",
      "Iter 400/1000 - Loss: 1.970   lengthscale: 1.205   noise: 1.425\n",
      "Iter 401/1000 - Loss: 1.970   lengthscale: 1.204   noise: 1.424\n",
      "Iter 402/1000 - Loss: 1.970   lengthscale: 1.204   noise: 1.424\n",
      "Iter 403/1000 - Loss: 1.970   lengthscale: 1.204   noise: 1.423\n",
      "Iter 404/1000 - Loss: 1.970   lengthscale: 1.204   noise: 1.423\n",
      "Iter 405/1000 - Loss: 1.970   lengthscale: 1.204   noise: 1.423\n",
      "Iter 406/1000 - Loss: 1.970   lengthscale: 1.203   noise: 1.422\n",
      "Iter 407/1000 - Loss: 1.970   lengthscale: 1.203   noise: 1.422\n",
      "Iter 408/1000 - Loss: 1.970   lengthscale: 1.203   noise: 1.422\n",
      "Iter 409/1000 - Loss: 1.970   lengthscale: 1.203   noise: 1.421\n",
      "Iter 410/1000 - Loss: 1.970   lengthscale: 1.203   noise: 1.421\n",
      "Iter 411/1000 - Loss: 1.970   lengthscale: 1.202   noise: 1.420\n",
      "Iter 412/1000 - Loss: 1.970   lengthscale: 1.202   noise: 1.420\n",
      "Iter 413/1000 - Loss: 1.970   lengthscale: 1.202   noise: 1.420\n",
      "Iter 414/1000 - Loss: 1.970   lengthscale: 1.202   noise: 1.419\n",
      "Iter 415/1000 - Loss: 1.970   lengthscale: 1.202   noise: 1.419\n",
      "Iter 416/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.419\n",
      "Iter 417/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.418\n",
      "Iter 418/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.418\n",
      "Iter 419/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.417\n",
      "Iter 420/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.417\n",
      "Iter 421/1000 - Loss: 1.970   lengthscale: 1.201   noise: 1.417\n",
      "Iter 422/1000 - Loss: 1.970   lengthscale: 1.200   noise: 1.416\n",
      "Iter 423/1000 - Loss: 1.970   lengthscale: 1.200   noise: 1.416\n",
      "Iter 424/1000 - Loss: 1.970   lengthscale: 1.200   noise: 1.416\n",
      "Iter 425/1000 - Loss: 1.970   lengthscale: 1.200   noise: 1.415\n",
      "Iter 426/1000 - Loss: 1.970   lengthscale: 1.200   noise: 1.415\n",
      "Iter 427/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.414\n",
      "Iter 428/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.414\n",
      "Iter 429/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.414\n",
      "Iter 430/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.413\n",
      "Iter 431/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.413\n",
      "Iter 432/1000 - Loss: 1.970   lengthscale: 1.199   noise: 1.413\n",
      "Iter 433/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.412\n",
      "Iter 434/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.412\n",
      "Iter 435/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.412\n",
      "Iter 436/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.411\n",
      "Iter 437/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.411\n",
      "Iter 438/1000 - Loss: 1.970   lengthscale: 1.198   noise: 1.410\n",
      "Iter 439/1000 - Loss: 1.970   lengthscale: 1.197   noise: 1.410\n",
      "Iter 440/1000 - Loss: 1.970   lengthscale: 1.197   noise: 1.410\n",
      "Iter 441/1000 - Loss: 1.970   lengthscale: 1.197   noise: 1.409\n",
      "Iter 442/1000 - Loss: 1.970   lengthscale: 1.197   noise: 1.409\n",
      "Iter 443/1000 - Loss: 1.970   lengthscale: 1.197   noise: 1.409\n",
      "Iter 444/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.408\n",
      "Iter 445/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.408\n",
      "Iter 446/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.408\n",
      "Iter 447/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.407\n",
      "Iter 448/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.407\n",
      "Iter 449/1000 - Loss: 1.970   lengthscale: 1.196   noise: 1.407\n",
      "Iter 450/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.406\n",
      "Iter 451/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.406\n",
      "Iter 452/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.406\n",
      "Iter 453/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.405\n",
      "Iter 454/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.405\n",
      "Iter 455/1000 - Loss: 1.970   lengthscale: 1.195   noise: 1.405\n",
      "Iter 456/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.404\n",
      "Iter 457/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.404\n",
      "Iter 458/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.404\n",
      "Iter 459/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.403\n",
      "Iter 460/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.403\n",
      "Iter 461/1000 - Loss: 1.970   lengthscale: 1.194   noise: 1.403\n",
      "Iter 462/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.402\n",
      "Iter 463/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.402\n",
      "Iter 464/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.402\n",
      "Iter 465/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.401\n",
      "Iter 466/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.401\n",
      "Iter 467/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.401\n",
      "Iter 468/1000 - Loss: 1.970   lengthscale: 1.193   noise: 1.400\n",
      "Iter 469/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.400\n",
      "Iter 470/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.400\n",
      "Iter 471/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.399\n",
      "Iter 472/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.399\n",
      "Iter 473/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.399\n",
      "Iter 474/1000 - Loss: 1.970   lengthscale: 1.192   noise: 1.398\n",
      "Iter 475/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.398\n",
      "Iter 476/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.398\n",
      "Iter 477/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.397\n",
      "Iter 478/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.397\n",
      "Iter 479/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.397\n",
      "Iter 480/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.396\n",
      "Iter 481/1000 - Loss: 1.970   lengthscale: 1.191   noise: 1.396\n",
      "Iter 482/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.396\n",
      "Iter 483/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.395\n",
      "Iter 484/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.395\n",
      "Iter 485/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.395\n",
      "Iter 486/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.394\n",
      "Iter 487/1000 - Loss: 1.970   lengthscale: 1.190   noise: 1.394\n",
      "Iter 488/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.394\n",
      "Iter 489/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.394\n",
      "Iter 490/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.393\n",
      "Iter 491/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.393\n",
      "Iter 492/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.393\n",
      "Iter 493/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.392\n",
      "Iter 494/1000 - Loss: 1.970   lengthscale: 1.189   noise: 1.392\n",
      "Iter 495/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.392\n",
      "Iter 496/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.391\n",
      "Iter 497/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.391\n",
      "Iter 498/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.391\n",
      "Iter 499/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.391\n",
      "Iter 500/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.390\n",
      "Iter 501/1000 - Loss: 1.970   lengthscale: 1.188   noise: 1.390\n",
      "Iter 502/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.390\n",
      "Iter 503/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.389\n",
      "Iter 504/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.389\n",
      "Iter 505/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.389\n",
      "Iter 506/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.388\n",
      "Iter 507/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.388\n",
      "Iter 508/1000 - Loss: 1.970   lengthscale: 1.187   noise: 1.388\n",
      "Iter 509/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.388\n",
      "Iter 510/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.387\n",
      "Iter 511/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.387\n",
      "Iter 512/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.387\n",
      "Iter 513/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 514/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.386\n",
      "Iter 515/1000 - Loss: 1.970   lengthscale: 1.186   noise: 1.386\n",
      "Iter 516/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.386\n",
      "Iter 517/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.385\n",
      "Iter 518/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.385\n",
      "Iter 519/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.385\n",
      "Iter 520/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.384\n",
      "Iter 521/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.384\n",
      "Iter 522/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.384\n",
      "Iter 523/1000 - Loss: 1.970   lengthscale: 1.185   noise: 1.384\n",
      "Iter 524/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.383\n",
      "Iter 525/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.383\n",
      "Iter 526/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.383\n",
      "Iter 527/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.382\n",
      "Iter 528/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.382\n",
      "Iter 529/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.382\n",
      "Iter 530/1000 - Loss: 1.970   lengthscale: 1.184   noise: 1.382\n",
      "Iter 531/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.381\n",
      "Iter 532/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.381\n",
      "Iter 533/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.381\n",
      "Iter 534/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.381\n",
      "Iter 535/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.380\n",
      "Iter 536/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.380\n",
      "Iter 537/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.380\n",
      "Iter 538/1000 - Loss: 1.970   lengthscale: 1.183   noise: 1.380\n",
      "Iter 539/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.379\n",
      "Iter 540/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.379\n",
      "Iter 541/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.379\n",
      "Iter 542/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.378\n",
      "Iter 543/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.378\n",
      "Iter 544/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.378\n",
      "Iter 545/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.378\n",
      "Iter 546/1000 - Loss: 1.970   lengthscale: 1.182   noise: 1.377\n",
      "Iter 547/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.377\n",
      "Iter 548/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.377\n",
      "Iter 549/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.377\n",
      "Iter 550/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.376\n",
      "Iter 551/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.376\n",
      "Iter 552/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.376\n",
      "Iter 553/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.376\n",
      "Iter 554/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.375\n",
      "Iter 555/1000 - Loss: 1.970   lengthscale: 1.181   noise: 1.375\n",
      "Iter 556/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.375\n",
      "Iter 557/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.375\n",
      "Iter 558/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.374\n",
      "Iter 559/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.374\n",
      "Iter 560/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.374\n",
      "Iter 561/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.374\n",
      "Iter 562/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.373\n",
      "Iter 563/1000 - Loss: 1.970   lengthscale: 1.180   noise: 1.373\n",
      "Iter 564/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.373\n",
      "Iter 565/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.373\n",
      "Iter 566/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.372\n",
      "Iter 567/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.372\n",
      "Iter 568/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.372\n",
      "Iter 569/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.372\n",
      "Iter 570/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.371\n",
      "Iter 571/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.371\n",
      "Iter 572/1000 - Loss: 1.970   lengthscale: 1.179   noise: 1.371\n",
      "Iter 573/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.371\n",
      "Iter 574/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.371\n",
      "Iter 575/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.370\n",
      "Iter 576/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.370\n",
      "Iter 577/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.370\n",
      "Iter 578/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.370\n",
      "Iter 579/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.369\n",
      "Iter 580/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.369\n",
      "Iter 581/1000 - Loss: 1.970   lengthscale: 1.178   noise: 1.369\n",
      "Iter 582/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.369\n",
      "Iter 583/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.368\n",
      "Iter 584/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.368\n",
      "Iter 585/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.368\n",
      "Iter 586/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.368\n",
      "Iter 587/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.368\n",
      "Iter 588/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.367\n",
      "Iter 589/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.367\n",
      "Iter 590/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.367\n",
      "Iter 591/1000 - Loss: 1.970   lengthscale: 1.177   noise: 1.367\n",
      "Iter 592/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.366\n",
      "Iter 593/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.366\n",
      "Iter 594/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.366\n",
      "Iter 595/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.366\n",
      "Iter 596/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.366\n",
      "Iter 597/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.365\n",
      "Iter 598/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.365\n",
      "Iter 599/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.365\n",
      "Iter 600/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.365\n",
      "Iter 601/1000 - Loss: 1.970   lengthscale: 1.176   noise: 1.364\n",
      "Iter 602/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.364\n",
      "Iter 603/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.364\n",
      "Iter 604/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.364\n",
      "Iter 605/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.364\n",
      "Iter 606/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.363\n",
      "Iter 607/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.363\n",
      "Iter 608/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.363\n",
      "Iter 609/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.363\n",
      "Iter 610/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.363\n",
      "Iter 611/1000 - Loss: 1.970   lengthscale: 1.175   noise: 1.362\n",
      "Iter 612/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.362\n",
      "Iter 613/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.362\n",
      "Iter 614/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.362\n",
      "Iter 615/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.361\n",
      "Iter 616/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.361\n",
      "Iter 617/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.361\n",
      "Iter 618/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.361\n",
      "Iter 619/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.361\n",
      "Iter 620/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.360\n",
      "Iter 621/1000 - Loss: 1.970   lengthscale: 1.174   noise: 1.360\n",
      "Iter 622/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.360\n",
      "Iter 623/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.360\n",
      "Iter 624/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.360\n",
      "Iter 625/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.359\n",
      "Iter 626/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.359\n",
      "Iter 627/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.359\n",
      "Iter 628/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.359\n",
      "Iter 629/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.359\n",
      "Iter 630/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.358\n",
      "Iter 631/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.358\n",
      "Iter 632/1000 - Loss: 1.970   lengthscale: 1.173   noise: 1.358\n",
      "Iter 633/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.358\n",
      "Iter 634/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.358\n",
      "Iter 635/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.358\n",
      "Iter 636/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.357\n",
      "Iter 637/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.357\n",
      "Iter 638/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.357\n",
      "Iter 639/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.357\n",
      "Iter 640/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.357\n",
      "Iter 641/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 642/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.356\n",
      "Iter 643/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.356\n",
      "Iter 644/1000 - Loss: 1.970   lengthscale: 1.172   noise: 1.356\n",
      "Iter 645/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.356\n",
      "Iter 646/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 647/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 648/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 649/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 650/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 651/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.355\n",
      "Iter 652/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.354\n",
      "Iter 653/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.354\n",
      "Iter 654/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.354\n",
      "Iter 655/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.354\n",
      "Iter 656/1000 - Loss: 1.970   lengthscale: 1.171   noise: 1.354\n",
      "Iter 657/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 658/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 659/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 660/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 661/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 662/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.353\n",
      "Iter 663/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 664/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 665/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 666/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 667/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 668/1000 - Loss: 1.970   lengthscale: 1.170   noise: 1.352\n",
      "Iter 669/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 670/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 671/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 672/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 673/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 674/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.351\n",
      "Iter 675/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 676/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 677/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 678/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 679/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 680/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.350\n",
      "Iter 681/1000 - Loss: 1.970   lengthscale: 1.169   noise: 1.349\n",
      "Iter 682/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.349\n",
      "Iter 683/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.349\n",
      "Iter 684/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.349\n",
      "Iter 685/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.349\n",
      "Iter 686/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.349\n",
      "Iter 687/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 688/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 689/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 690/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 691/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 692/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.348\n",
      "Iter 693/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.347\n",
      "Iter 694/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.347\n",
      "Iter 695/1000 - Loss: 1.970   lengthscale: 1.168   noise: 1.347\n",
      "Iter 696/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.347\n",
      "Iter 697/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.347\n",
      "Iter 698/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.347\n",
      "Iter 699/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.347\n",
      "Iter 700/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 701/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 702/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 703/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 704/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 705/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 706/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.346\n",
      "Iter 707/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.345\n",
      "Iter 708/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.345\n",
      "Iter 709/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.345\n",
      "Iter 710/1000 - Loss: 1.970   lengthscale: 1.167   noise: 1.345\n",
      "Iter 711/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.345\n",
      "Iter 712/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.345\n",
      "Iter 713/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.345\n",
      "Iter 714/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 715/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 716/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 717/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 718/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 719/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 720/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.344\n",
      "Iter 721/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.343\n",
      "Iter 722/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.343\n",
      "Iter 723/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.343\n",
      "Iter 724/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.343\n",
      "Iter 725/1000 - Loss: 1.970   lengthscale: 1.166   noise: 1.343\n",
      "Iter 726/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.343\n",
      "Iter 727/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.343\n",
      "Iter 728/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 729/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 730/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 731/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 732/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 733/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 734/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.342\n",
      "Iter 735/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 736/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 737/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 738/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 739/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 740/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 741/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 742/1000 - Loss: 1.970   lengthscale: 1.165   noise: 1.341\n",
      "Iter 743/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 744/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 745/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 746/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 747/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 748/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 749/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 750/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.340\n",
      "Iter 751/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 752/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 753/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 754/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 755/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 756/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 757/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 758/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.339\n",
      "Iter 759/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.338\n",
      "Iter 760/1000 - Loss: 1.970   lengthscale: 1.164   noise: 1.338\n",
      "Iter 761/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 762/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 763/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 764/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 765/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 766/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 767/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.338\n",
      "Iter 768/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 769/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 770/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 771/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 772/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 773/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 774/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 775/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 776/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.337\n",
      "Iter 777/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.336\n",
      "Iter 778/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.336\n",
      "Iter 779/1000 - Loss: 1.970   lengthscale: 1.163   noise: 1.336\n",
      "Iter 780/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 781/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 782/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 783/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 784/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 785/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.336\n",
      "Iter 786/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 787/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 788/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 789/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 790/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 791/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 792/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 793/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 794/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.335\n",
      "Iter 795/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 796/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 797/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 798/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 799/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 800/1000 - Loss: 1.970   lengthscale: 1.162   noise: 1.334\n",
      "Iter 801/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.334\n",
      "Iter 802/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.334\n",
      "Iter 803/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.334\n",
      "Iter 804/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.334\n",
      "Iter 805/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 806/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 807/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 808/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 809/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 810/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 811/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 812/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 813/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 814/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.333\n",
      "Iter 815/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 816/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 817/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 818/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 819/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 820/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 821/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 822/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 823/1000 - Loss: 1.970   lengthscale: 1.161   noise: 1.332\n",
      "Iter 824/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.332\n",
      "Iter 825/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.332\n",
      "Iter 826/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 827/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 828/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 829/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 830/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 831/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 832/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 833/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 834/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 835/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 836/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.331\n",
      "Iter 837/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 838/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 839/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 840/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 841/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 842/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 843/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 844/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 845/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 846/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 847/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 848/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.330\n",
      "Iter 849/1000 - Loss: 1.970   lengthscale: 1.160   noise: 1.329\n",
      "Iter 850/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 851/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 852/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 853/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 854/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 855/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 856/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 857/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 858/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 859/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 860/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 861/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.329\n",
      "Iter 862/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 863/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 864/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 865/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 866/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 867/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 868/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 869/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 870/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 871/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 872/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 873/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 874/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.328\n",
      "Iter 875/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.327\n",
      "Iter 876/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.327\n",
      "Iter 877/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.327\n",
      "Iter 878/1000 - Loss: 1.970   lengthscale: 1.159   noise: 1.327\n",
      "Iter 879/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 880/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 881/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 882/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 883/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 884/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 885/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 886/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 887/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 888/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.327\n",
      "Iter 889/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 890/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 891/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 892/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 893/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 894/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 895/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 896/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 897/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 898/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 899/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 900/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 901/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 902/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 903/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.326\n",
      "Iter 904/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 905/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 906/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 907/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 908/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 909/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 910/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 911/1000 - Loss: 1.970   lengthscale: 1.158   noise: 1.325\n",
      "Iter 912/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 913/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 914/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 915/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 916/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 917/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 918/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 919/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 920/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.325\n",
      "Iter 921/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 922/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 923/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 924/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 925/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 926/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 927/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 928/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 929/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 930/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 931/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 932/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 933/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 934/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 935/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 936/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 937/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.324\n",
      "Iter 938/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 939/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 940/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 941/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 942/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 943/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 944/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 945/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 946/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 947/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 948/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 949/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 950/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 951/1000 - Loss: 1.970   lengthscale: 1.157   noise: 1.323\n",
      "Iter 952/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.323\n",
      "Iter 953/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.323\n",
      "Iter 954/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.323\n",
      "Iter 955/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.323\n",
      "Iter 956/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.323\n",
      "Iter 957/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 958/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 959/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 960/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 961/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 962/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 963/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 964/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 965/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 966/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 967/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 968/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 969/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 970/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 971/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 972/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 973/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 974/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 975/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 976/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 977/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 978/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.322\n",
      "Iter 979/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 980/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 981/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 982/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 983/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 984/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 985/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 986/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 987/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 988/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 989/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 990/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 991/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 992/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 993/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 994/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 995/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 996/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 997/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 998/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 999/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n",
      "Iter 1000/1000 - Loss: 1.970   lengthscale: 1.156   noise: 1.321\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training the GP models: \n",
    "A) GPyTorch was used to fit a GP with RBF Kernel\n",
    "B) The simplest likelihood for regression is the gpytorch.likelihoods.GaussianLikelihood.\n",
    "This assumes a homoskedastic noise model (i.e. all inputs have the same observational noise).\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# this is for running the notebook in our testing framework\n",
    "import os\n",
    "smoke_test = ('CI' in os.environ)\n",
    "training_iter = 2 if smoke_test else 1000\n",
    "\n",
    "\"\"\"\n",
    "TRAINING MODEL 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Find optimal model hyperparameters\n",
    "model1.train()\n",
    "likelihood.train()\n",
    "\n",
    "# Use the adam optimizer\n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.1)  # Includes GaussianLikelihood parameters\n",
    "\n",
    "\"\"\" Add link to the place where the code has been taken from\n",
    "\"\"\"\n",
    "\n",
    "# \"Loss\" for GPs - the marginal log likelihood\n",
    "mll1 = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model1)\n",
    "\n",
    "for i in range(training_iter):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer1.zero_grad()\n",
    "    # Output from model\n",
    "    output = model1(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll1(output, train_y1)\n",
    "    loss.backward()\n",
    "    print('Iter %d/%d - Loss: %.3f   lengthscale: %.3f   noise: %.3f' % (\n",
    "        i + 1, training_iter, loss.item(),\n",
    "        model1.covar_module.base_kernel.lengthscale.item(),\n",
    "        model1.likelihood.noise.item()\n",
    "    ))\n",
    "    optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This section of the code makes prediction for the trained GP model on PC-1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Get into evaluation (predictive posterior) mode\n",
    "model1.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred1 = likelihood(model1(test_x))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    # Calculating upper and lower bounds of model predictions\n",
    "    lower1, upper1 = observed_pred1.confidence_region()\n",
    "    # converting upper and lower bound prediction sto numpy array\n",
    "    lower1_numpy = lower1.numpy()\n",
    "    upper1_numpy = upper1.numpy()\n",
    "    # Claculating mean prediction\n",
    "    output_model_predictions_1 = observed_pred1.mean.numpy()\n",
    "    # fetching actual output data\n",
    "    original_output = test_y1\n",
    "\n",
    "# Calculating total error in predictions    \n",
    "error_prediction = np.subtract(upper1_numpy, lower1_numpy)\n",
    "# Plotting model predictions for PC1\n",
    "#print(np.amin(original_output))\n",
    "\n",
    "# Discretizing coordinate system for updating the parietal_plots\n",
    "x_par = np.linspace(np.amin(original_output),np.amax(original_output), num = 100)\n",
    "# Plotting the parietal line y = x\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(x_par, x_par)\n",
    "# Plotting the output predictions against known output value\n",
    "ax.plot(original_output, output_model_predictions_1, 'o', color='black')\n",
    "# Plotting the errorbars\n",
    "ax.errorbar(original_output, output_model_predictions_1,\n",
    "             yerr = error_prediction, lolims = lower1_numpy, uplims = upper1_numpy, linestyle = \"None\")\n",
    "# Labelling the axes\n",
    "#ax.fill_between(original_output, upper1_numpy, lower1_numpy, facecolor='blue', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel(\" True PC-8\")\n",
    "ax.set_ylabel(\" Predicted PC-8\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
