{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spatial_efd\n",
    "import math \n",
    "import signac\n",
    "import numpy as np\n",
    "import os.path\n",
    "import os\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import similaritymeasures\n",
    "#from smt.sampling_methods import LHS\n",
    "# Importing helper libraries for bayesian optimization\n",
    "from dependencies.data_preprocessing_class import dataPreprocessing\n",
    "from dependencies.gaussian_process_regression_class import gaussianProcessRegression\n",
    "from dependencies.acquisition_functions_class import acqisitionFunctions\n",
    "from dependencies.geometry_writer import geometryWriter\n",
    "from dependencies.feature_extractor_4 import FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Reducing feature data dimensionality \n",
    "\n",
    "1. For comptation of sensitivity, simulations are run by increasing and decreasing parameter values by 70%. For each simulation run we record, a) Edge length of individual components b) local curvature extimated at each vertex on the basal surface c) frechet error measuring deviation of apical and basl surface from the equilibrium tissue shape. Parameters varied: '$T^{squ}_{B}$','$T^{cub}_{B}$','$T^{col}_{B}$','$k^{squ}_{A}$','$k^{squ}_{B}$','$k^{squ}_{L}$','$k^{cub}_{A}$','$k^{cub}_{B}$','$k^{cub}_{L}$','$k^{col}_{A}$','$k^{col}_{B}$','$k^{col}_{L}$','$Lo^{squ}_{A}$','$Lo^{squ}_{B}$','$Lo^{squ}_{L}$','$Lo^{cub}_{A}$','$Lo^{cub}_{B}$','$Lo^{cub}_{L}$','$Lo^{col}_{A}$','$Lo^{col}_{B}$','$Lo^{col}_{L}$','$K_{ECM}$'\n",
    "\n",
    "\n",
    "2. Measured Morphological changes and reduction of dimensionality\n",
    "    - Converting edge length matrix into eaningful measurable wing disc cell lengths.\n",
    "    - Converting or splitting curvature to approximate the curvature of basal surface adhering to the columnar cells.\n",
    "    - Loading the frechet error for approximation of the apical and basal surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tissue_edge_length_master.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-c56941198667>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdf_identity\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'edge_length_identity.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Loading the master data containing edge lengths in columns (390) for all the samples in row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mtissue_edge_length_master\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tissue_edge_length_master.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;31m# Labels for individual ege length types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0medge_length_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'$L^{col}_{A}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{col}_{B}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{col}_{L}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{cub}_{A}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{cub}_{B}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{cub, col}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{cub}_{L}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{squ}_{A}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{squ}_{B}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{squ, cub}$'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'$L^{squ}_{L}$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m             \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tissue_edge_length_master.npy'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"  Step 1: Transforming the cell lengths\n",
    "Inputs:\n",
    "     i) tissue_edge_length_master: edge lengths of all the cells for samples from parameter screen. It is a \n",
    "                                   [n_samples x 390] array\n",
    "     ii) edge_length_identity: Each of the 390 edge lengths belong to a specific cell type class. The array \n",
    "                               contains 390 labels for each edge type\n",
    "\n",
    "Output: \n",
    "     i) tissue_edge_length_t : The edge lengths are trucated as mean values of edge lengths belonging to a \n",
    "                               particular calss of cell type. Its a n_samples x 11 array. We have a total of \n",
    "                               11 different edge ypes  \"\"\"\n",
    "\n",
    "# Defining the total number of simulations\n",
    "n_simulation = 44\n",
    "# Reading the excel sheet containiing identity of all the 390 cell types\n",
    "df_identity = pd.read_excel ('edge_length_identity.xlsx')\n",
    "# Loading the master data containing edge lengths in columns (390) for all the samples in row\n",
    "tissue_edge_length_master = np.load('output_data_files/tissue_edge_length_master.npy')\n",
    "# Labels for individual ege length types\n",
    "edge_length_labels = ('$L^{col}_{A}$', '$L^{col}_{B}$', '$L^{col}_{L}$', '$L^{cub}_{A}$', '$L^{cub}_{B}$', '$L^{cub, col}$', '$L^{cub}_{L}$', '$L^{squ}_{A}$', '$L^{squ}_{B}$', '$L^{squ, cub}$', '$L^{squ}_{L}$')         \n",
    "# Initializing truncated edge length array\n",
    "tissue_edge_length_t = np.zeros((n_simulation,11))\n",
    "# Iterating through each sample to truncate the edge lengths\n",
    "for i in range(n_simulation):\n",
    "    # edge length for the nth sample\n",
    "    iter_edge_length = tissue_edge_length_master[i,:]\n",
    "    # reshaping the array as a column array for truncation\n",
    "    iter_edge_length_r = np.reshape(iter_edge_length,(390,1))\n",
    "    # creating two data frames of edge lengths and their identities\n",
    "    df_edge_length = pd.DataFrame(iter_edge_length_r, columns = ['SE_edge_length'])\n",
    "    df_iter = pd.concat([df_identity, df_edge_length], axis=1)\n",
    "    # Use the grouping feature of dataframes to compute mean edge length for each cell type\n",
    "    x = df_iter.groupby('identity').mean().values\n",
    "    # Storing the truncated values in master truncated edge length rray\n",
    "    tissue_edge_length_t[i,:] = np.reshape(x,(1,11))\n",
    "\n",
    "\"\"\"  Step 2: Tranforming the curvature\n",
    "\n",
    "Inputs: \n",
    "    i) curvature_basal_master: An array of shape [n_samples x n_curv_points] containing local curvature of the basal epithelia\n",
    "\n",
    "Outputs: \n",
    "    ii) curvature_basal_t :  Average basal curvature for columnar tissue computed at the medial and lateral ends.\n",
    "                             Shape - [n_samples x 3] \"\"\"\n",
    "\n",
    "# Loading the array containing curvature data from the sensitivity screening\n",
    "curvature_basal_master = np.load('output_data_files/curvature_basal_master.npy')\n",
    "# Extracting the curvature of the bsala columnar epithelia\n",
    "curvature_basal_master_columnar = curvature_basal_master[:,16:116]\n",
    "# Initializing the array theat will store the truncated average curvature within the basal epithelia\n",
    "curvature_basal_t = np.zeros((n_simulation,3))\n",
    "# Extracting curvature values of three equal domains representing the medial basal and two mlateral basal domains\n",
    "curv_right = curvature_basal_master_columnar[:,0:25]\n",
    "curv_center = curvature_basal_master_columnar[:,25:75]\n",
    "curv_left = curvature_basal_master_columnar[:,75:100]\n",
    "# Computing average curvature values for the three domains\n",
    "curv_right_average = np.mean(curv_right, axis = 1)\n",
    "curv_center_average = np.mean(curv_center, axis = 1)\n",
    "curv_left_average = np.mean(curv_left, axis = 1)\n",
    "# Storing the truncated currvatures in masater array\n",
    "curvature_basal_t[:,0] = curv_right_average \n",
    "curvature_basal_t[:,1] = curv_center_average\n",
    "curvature_basal_t[:,2] = curv_left_average\n",
    "\n",
    "\n",
    "\"\"\"  Step 3: Loading frechet error for upper and lower parameter bounds  \"\"\"\n",
    "\n",
    "error_target_sampled_apical = np.load('output_data_files/error_target_sampled_apical.npy')\n",
    "error_target_sampled_basal = np.load('output_data_files/error_target_sampled_basal.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing sensitivities for different features\n",
    "\n",
    "1. Central difference scheme was used to compute sensitivities: $ S_P = \\frac{F_{P + \\delta_{P}} - F_{P - \\delta_{P}}}{2\\delta_{P}} $ where,\n",
    "    - $S_P$ denotes the sensitivity of a particular parameter P\n",
    "    - $ \\delta_{P} $ represents samll perturbation in the parameter value (70%)\n",
    "    - $ F $ represents the value of a particular feature say height or frechet error for the parameter value P.\n",
    "\n",
    "\n",
    "2. Different geometric features whose changes were measured on variation of parameters:\n",
    "    - Frechet error for apical surface, 1\n",
    "    - Frechet error for thr basal surface, 1\n",
    "    - Truncated cell lengths (columnar only, 11)\n",
    "    - Truncated basal curvatures, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This portion of the code computes sensitivitiy in shape features upon variation of model parameters using\n",
    "the finite difference formulae. \n",
    "\n",
    "Sensitivity can be compued using two different ways based on the choice of calc_method parameter.\n",
    "calc_method == 1 : Actual change in parameter values is used\n",
    "calc_method == 2 : Percentage change in parameter value is used (0.7)\n",
    "\n",
    "\"\"\"\n",
    "calc_method = 2\n",
    "# number of parameters varied\n",
    "n_param = 22\n",
    "# param values around equilibrium\n",
    "val_param = [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
    "# Initialization of arrays to store sensitivities in features upon perturbation of parameters\n",
    "sens_frechet_apical = np.zeros((n_param,))\n",
    "sens_frechet_basal = np.zeros((n_param,))\n",
    "sens_curv = np.zeros((n_param,3))\n",
    "sens_cell_length = np.zeros((n_param,11))\n",
    "\n",
    "# Calculating sensitivities for different parameters using the formulae above\n",
    "for i in range(22):\n",
    "    # Defining choice of sensitivity calculation\n",
    "    if calc_method == 1:\n",
    "        d_theta = 0.7*param_val[i]\n",
    "    elif calc_method == 2:\n",
    "        d_theta = 0.7\n",
    "    sens_frechet_apical[i] = (error_target_sampled_apical[2*i + 1] - error_target_sampled_apical[2*i]) / (2*d_theta)\n",
    "    sens_frechet_basal[i] = (error_target_sampled_basal[2*i + 1] - error_target_sampled_basal[2*i]) / (2*d_theta)\n",
    "    sens_curv[i,:] = np.subtract(curvature_basal_t[2*i+1,:], curvature_basal_t[2*i,:]) / (2*d_theta)\n",
    "    sens_cell_length[i,:] = np.subtract(tissue_edge_length_t[2*i+1,:], tissue_edge_length_t[2*i,:]) / (2*d_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of parameters in the sampling for screening    \n",
    "params_lhs = ('T_squ_b','T_cub_b','T_col_b','k_squ_a','k_squ_b','k_squ_l','k_cub_a','k_cub_b','k_cub_l','k_col_a','k_col_b','k_col_l','lo_squ_a','lo_squ_b','lo_squ_l','lo_cub_a','lo_cub_b','lo_cub_l','lo_col_a','lo_col_b','lo_col_l','K_ECM')\n",
    "# Defining the size (figsize) and resolution (dpi) of figure\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, sharex=True, sharey=True, figsize=(10, 5), dpi=600)\n",
    "\n",
    "\"\"\"  Step 1: Plotting sensitivity in Frechet errors  \"\"\"\n",
    "\n",
    "# Positioning the bars at equal intervals. Number of bars for each subplot\n",
    "# equals the number of parameters that were varied.\n",
    "y_pos = np.arange(len(params_lhs))\n",
    "# Subplot 1: Sensitivity in apical frechet error\n",
    "plt.subplot(4, 4, 1)\n",
    "# Using matplotlib to plot sensitivities for frechet error apical in define positions on the x axis\n",
    "plt.bar(y_pos, np.log(np.abs(sens_frechet_apical)))\n",
    "# Turing off ticks in the scale\n",
    "plt.xticks([])\n",
    "# Changing the fontsize of y axis\n",
    "plt.yticks(fontsize=6)\n",
    "# Defining title of the plot representing the feature for which sensitivityt was measured\n",
    "plt.title('$F_{A}$', fontsize=10)\n",
    "# Subplot 1: Sensitivity in basal frechet error\n",
    "plt.subplot(4, 4, 2)\n",
    "plt.bar(y_pos, np.log(np.abs(sens_frechet_basal)))\n",
    "plt.xticks(y_pos, params_lhs)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=6)\n",
    "plt.title('$F_{B}$', fontsize=10)\n",
    "\n",
    "\"\"\"  Step 2: Plotting sensitivity in curvatures  \"\"\"\n",
    "\n",
    "# Subplot 3\n",
    "plt.subplot(4, 4, 3)\n",
    "plt.bar(y_pos, np.log(np.abs(sens_curv[:,0])))\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=6)\n",
    "plt.title('$\\kappa_{Posterior}$', fontsize=10)\n",
    "# Subplot 4\n",
    "plt.subplot(4, 4, 4)\n",
    "plt.bar(y_pos, np.log(np.abs(sens_curv[:,1])))\n",
    "plt.xticks(y_pos, params_lhs)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=6)\n",
    "plt.title('$\\kappa_{Central}$',fontsize=10)\n",
    "# Subplot 5\n",
    "plt.subplot(4, 4, 5)\n",
    "plt.bar(y_pos, np.log(np.abs(sens_curv[:,2])))\n",
    "plt.xticks(y_pos, params_lhs)\n",
    "plt.xticks([])\n",
    "plt.yticks(fontsize=6)\n",
    "plt.title('$\\kappa_{Anterior}$',fontsize=10)\n",
    "\n",
    "\"\"\"  Step 3: Plotting sensitivity in cell height  \"\"\"\n",
    "\n",
    "for i in range(11):\n",
    "    if i < 7:\n",
    "        plt.subplot(4, 4, 5+i+1)\n",
    "        plt.bar(y_pos, np.log(np.abs(sens_cell_length[:,i])))\n",
    "        plt.xticks([])\n",
    "        plt.yticks(fontsize=6)\n",
    "        plt.title(edge_length_labels[i], fontsize=10)\n",
    "    # Printing x labels in the bar plots of last row\n",
    "    elif i >= 7:\n",
    "        plt.subplot(4, 4, 5+i+1)\n",
    "        plt.bar(y_pos, np.log(np.abs(sens_cell_length[:,i])))\n",
    "        plt.xticks(y_pos, params_lhs)\n",
    "        plt.xticks(rotation = 90)\n",
    "        plt.xticks(fontsize=6)\n",
    "        plt.yticks(fontsize=6)\n",
    "        plt.title(edge_length_labels[i], fontsize=10)\n",
    "    \n",
    "\n",
    "\"\"\"  Final figure adjustments  \"\"\"\n",
    "\n",
    "# Making the spaces between the subplots uniform\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "# Deining the label of y axis for all the sublots. Placing it in the left hand side of the figure.\n",
    "fig.text(0.073, 0.5, '$log(abs(\\Theta_{0}(df/d\\Theta)))$', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.95, '$f$', ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 1: Barplots describing sensitivities of all the measured geometrical features upon perturbation of model parameters.__  A total of 16 geometrical features whose sensitivity is measures are listed as heading of each subplot. Labels in the x axis of each plot represent the model parameters that were varied against which the sensitivity was cmputed.*Note: Log of absolute value of sensitivity has been plotted*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the master sensitivity matrix by horizontally concatenating each column representing a particular geometrical feature .\n",
    "sens_master = np.hstack((np.reshape(sens_frechet_apical,(22,1)),np.reshape(sens_frechet_basal,(22,1)),sens_curv, sens_cell_length))\n",
    "# Scaling the sensitivity wrt to mean \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "sens_master_scaled = sc.fit_transform(sens_master)\n",
    "\n",
    "\"\"\" Plotting \"\"\"\n",
    "\n",
    "# Importing seaborn for visualization of the sensitivity array\n",
    "import seaborn as sns\n",
    "# Defining labels of features and parameters\n",
    "x_label = ('$F_{A}$','$F_{B}$')+('$\\kappa_{Posterior}$','$\\kappa_{Central}$','$\\kappa_{Anterior}$')+ edge_length_labels\n",
    "params_lhs = ('$T^{squ}_{B}$','$T^{cub}_{B}$','$T^{col}_{B}$','$k^{squ}_{A}$','$k^{squ}_{B}$','$k^{squ}_{L}$','$k^{cub}_{A}$','$k^{cub}_{B}$','$k^{cub}_{L}$','$k^{col}_{A}$','$k^{col}_{B}$','$k^{col}_{L}$','$Lo^{squ}_{A}$','$Lo^{squ}_{B}$','$Lo^{squ}_{L}$','$Lo^{cub}_{A}$','$Lo^{cub}_{B}$','$Lo^{cub}_{L}$','$Lo^{col}_{A}$','$Lo^{col}_{B}$','$Lo^{col}_{L}$','$K_{ECM}$')\n",
    "# Defining the resolution of the figure\n",
    "sns.set(rc={\"figure.dpi\":600, 'savefig.dpi':600})\n",
    "# Defining the size of figure\n",
    "sns.set(rc={'figure.figsize':(2.25,3)})\n",
    "# Using seaborn to plot visualize the array as a heatmap\n",
    "ax = sns.heatmap(np.abs(sens_master_scaled), xticklabels = x_label, yticklabels = params_lhs, linewidths=.3, cmap=\"YlGnBu\", cbar_kws={'label': '$abs(\\Theta_{0}(df/d\\Theta))$'})\n",
    "# Labelling the axes\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 5)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 5)\n",
    "ax.set_ylabel('$Input - \\Theta$', fontsize=7)\n",
    "ax.set_xlabel('$Output - f$', fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 2: Plotting heatmaps of sensitivities.__ *Notes: __(A)__ A master sensitivity array is defined where evry column represents sensitivity in a particular feature (row). Each row     represents the total parameters that were varied during the sensitivity analysis. Shape [n_param x n_feature] __(B)__ Scaled and non-scaled senitivities are plotted*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculating Fischer Information matrices\n",
    "\n",
    "1. This analysis has to be disregarded for Frechet errors. Other features are used to define a least square objective function and the aproximation of hessian () ~ jacobian x transpose(jacobian) holds true. The analysis involves:\n",
    "    - 22 ($n_{param}$) model parameters : $T^{squ}_{B}$,$T^{cub}_{B}$,$T^{col}_{B}$,$k^{squ}_{A}$,$k^{squ}_{B}$,$k^{squ}_{L}$,$k^{cub}_{A}$,$k^{cub}_{B}$,$k^{cub}_{L}$,$k^{col}_{A}$,$k^{col}_{B}$,$k^{col}_{L}$,$Lo^{squ}_{A}$,$Lo^{squ}_{B}$,$Lo^{squ}_{L}$,$Lo^{cub}_{A}$,$Lo^{cub}_{B}$,$Lo^{cub}_{L}$,$Lo^{col}_{A}$,$Lo^{col}_{B}$,$Lo^{col}_{L}$,$K_{ECM}$\n",
    "    - 16 ($n_{F}$) morphological featires: $F_{A}$,$F_{B}$,$\\kappa_{Posterior}$',$\\kappa_{Central}$,$\\kappa_{Anterior}$, $L^{col}_{A}$,$L^{col}_{B}$,$L^{col}_{L}$,$L^{cub}_{A}$,$L^{cub}_{B}$,$L^{cub, col}$,$L^{cub}_{L}$, $L^{squ}_{A}$',$L^{squ}_{B}$,$L^{squ, cub}$',$L^{squ}_{L}$\n",
    "\n",
    "2. Stwps followed\n",
    "    - For each morphological feature jacobian ($J$) is defined $n_{param}$ x 1 shaped column array.\n",
    "    - Hessian ($H$) is approximated as $JJ^{T}$ and is of the dimension $n_{param}$ x $n_{param}$\n",
    "    - The matrix is symmetric hence *np.linalg.eigh* is used to compute the eigenvalues and eigenvectors\n",
    "    - $H$ is scaled by square of standard deviation of the $J$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import linalg\n",
    "\n",
    "# Defining the number of parameters and number of features in the study\n",
    "num_param = 22\n",
    "num_feature = 16\n",
    "\n",
    "# Storing real and complex part of eigenvalues to ensure correctness in eigenvalue calculations\n",
    "fim_eig_real = np.zeros((num_feature,num_param))\n",
    "fim_eig_complex = np.zeros((num_feature,num_param))\n",
    "\n",
    "# Defining properties of figures \n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8), sharey=True, dpi=600)\n",
    "# Initializing counter\n",
    "k = 0\n",
    "\n",
    "# Loop over all  the jacobians of inmdividual features\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # Fetching jacobian of individual features from the master sensitivity matrix\n",
    "        jacobian_feature = np.reshape(sens_master[:,k],(num_param,1))\n",
    "        # calculate fischer information matrix\n",
    "        # Note: Scaling wrt variance of jacobian has been done\n",
    "        fim_feature = np.matmul(jacobian_feature,jacobian_feature.transpose())/((np.std(jacobian_feature))**2)\n",
    "        # Calculate eigenvalue and eigenvectors of the symmetric matrix using eigh\n",
    "        fim_eigvalue, fim_eigenvector = np.linalg.eigh(fim_feature)\n",
    "        # Calculating the real part of eigenvalue\n",
    "        fim_eig_real[k,:] = np.reshape((np.real(fim_eigvalue)),(1,num_param))\n",
    "        # Calculating the complex part of the eigenvalue\n",
    "        fim_eig_complex[k,:] = np.reshape((np.imag(fim_eigvalue)),(1,num_param))\n",
    "        # Plotting FIMs as heatmaps using seaborn\n",
    "        hmap = sns.heatmap(fim_feature, xticklabels = params_lhs, yticklabels = params_lhs, linewidths=.02, cmap=\"YlGnBu\",ax=axes[i,j])\n",
    "        # Setting up the plot titles as the features for which FIM has been calculated\n",
    "        axes[i,j].set_title(x_label[k])\n",
    "        # Adding colorbar\n",
    "        cbar = hmap.collections[0].colorbar\n",
    "        # Setting up the labelsizes\n",
    "        cbar.ax.tick_params(labelsize=5)\n",
    "        # Setting up fornts for xtick and yticklabels\n",
    "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize = 3)\n",
    "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize = 3)\n",
    "        # Increasing the counter. Moving to th enxt feature\n",
    "        k = k + 1\n",
    "        \n",
    "# Increasing spacing between the subplots \n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 3: Plotting approximated FIM of different geometric features__ *Note: The morphological featre for which the FIM has been computed has been mentioned as a title in the plot.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. Plotting eigenvalues corresponding to hessian of each measurable features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining eigenvalue labels\n",
    "eig_labels = ('$eig_{1}$', '$eig_{2}$', '$eig_{3}$', '$eig_{4}$', '$eig_{5}$', '$eig_{6}$', '$eig_{7}$',\n",
    "              '$eig_{8}$', '$eig_{9}$', '$eig_{10}$', '$eig_{11}$', '$eig_{12}$', '$eig_{13}$', '$eig_{14}$',\n",
    "              '$eig_{15}$', '$eig_{16}$', '$eig_{17}$', '$eig_{18}$', '$eig_{19}$', '$eig_{20}$', '$eig_{21}$', '$eig_{22}$')\n",
    "# Defining the figure size and type\n",
    "fig, ax = plt.subplots(nrows=4, ncols=4, sharex=True, sharey=True, figsize=(10, 6), dpi=600)\n",
    "# Define the position of bars within the x axis. Equals to numbers of parameters\n",
    "x_pos = np.arange(len(params_lhs))\n",
    "\n",
    "# Iterating over eigenvalues of each \n",
    "for i in range(16):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        # Plotting the eigenvalues against the define position in x axis\n",
    "        plt.bar(y_pos, fim_eig_real[i,:])\n",
    "        plt.xticks(x_pos, eig_labels)\n",
    "        # Rotating the label of xticks by 90 degrees\n",
    "        plt.xticks(rotation = 90)\n",
    "        # Defining the tick label sizes for x and y axis\n",
    "        plt.xticks(fontsize=6) \n",
    "        plt.yticks(fontsize=6)\n",
    "        # Turning logscale on in y direction\n",
    "        plt.yscale('log')\n",
    "        plt.title(x_label[i], fontsize=10)\n",
    "           \n",
    "# Adjusting vertical spacing between subplots            \n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "# Defining the x and y labels of plot\n",
    "fig.text(0.073, 0.5, '$Sorted$ $Eigenvalues$', va='center', rotation='vertical')\n",
    "fig.text(0.5, 0.95, '$Measurable$  $morphological$  $features$', ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Plotting eigenvectors corresponding to the largest eigenvalue of FIM for each morphological features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of parameters and number of features in the study\n",
    "num_param = 22\n",
    "num_feature = 16\n",
    "\n",
    "# Starting the iteration counter\n",
    "k = 0\n",
    "# Initializing the matrix for Storing eigenvectors corresponding to the maximum eigenvalues\n",
    "fim_evec_max_eval = np.zeros((num_feature,num_param))\n",
    "\n",
    "# Loop over all the jacobians of inmdividual features\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # Fetching jacobian of individual features from the master sensitivity matrix\n",
    "        jacobian_feature = np.reshape(sens_master[:,k],(num_param,1))\n",
    "        # calculate fischer information matrix\n",
    "        # Note: Scaling wrt variance of jacobian has been done\n",
    "        fim_feature = np.matmul(jacobian_feature,jacobian_feature.transpose())/((np.std(jacobian_feature))**2)\n",
    "        # Calculate eigenvalue and eigenvectors of the symmetric matrix using eigh\n",
    "        fim_eigvalue, fim_eigenvector = np.linalg.eigh(fim_feature)\n",
    "        # Since the eigenvalue is sorted. Selecting the last eigenvector corresponding to th eg reatest eigenvalue \n",
    "        fim_evec_max_eval[k,:] = np.reshape((fim_eigenvector[num_param-1,:]),(1,num_param))\n",
    "        # Managing iter counter\n",
    "        k = k + 1\n",
    "        \n",
    "\"\"\" Plotting the eigenvector matrix corresponding to maximum eigenvalues \"\"\"\n",
    "# Importing seaborn for visualization of the sensitivity array\n",
    "import seaborn as sns\n",
    "# Defining labels of features and parameters\n",
    "feature_label = ('$F_{A}$','$F_{B}$')+('$\\kappa_{Posterior}$','$\\kappa_{Central}$','$\\kappa_{Anterior}$')+ edge_length_labels\n",
    "params_lhs = ('$T^{squ}_{B}$','$T^{cub}_{B}$','$T^{col}_{B}$','$k^{squ}_{A}$','$k^{squ}_{B}$','$k^{squ}_{L}$','$k^{cub}_{A}$','$k^{cub}_{B}$','$k^{cub}_{L}$','$k^{col}_{A}$','$k^{col}_{B}$','$k^{col}_{L}$','$Lo^{squ}_{A}$','$Lo^{squ}_{B}$','$Lo^{squ}_{L}$','$Lo^{cub}_{A}$','$Lo^{cub}_{B}$','$Lo^{cub}_{L}$','$Lo^{col}_{A}$','$Lo^{col}_{B}$','$Lo^{col}_{L}$','$K_{ECM}$')\n",
    "# Defining the resolution of the figure\n",
    "sns.set(rc={\"figure.dpi\":600, 'savefig.dpi':600})\n",
    "# Defining the size of figure\n",
    "sns.set(rc={'figure.figsize':(4,2)})\n",
    "# Using seaborn to plot visualize the array as a heatmap\n",
    "ax = sns.heatmap(np.abs(fim_evec_max_eval), xticklabels = params_lhs, yticklabels = feature_label, linewidths=.3, cmap=\"YlGnBu\", cbar_kws={'label': '$abs(Eigenvector)$'})\n",
    "# Labelling the axes\n",
    "ax.set_xticklabels(ax.get_xmajorticklabels(), fontsize = 5)\n",
    "ax.set_yticklabels(ax.get_ymajorticklabels(), fontsize = 5)\n",
    "ax.set_ylabel('$Measurable$ $Morphological$ $Features$', fontsize=7)\n",
    "ax.set_xlabel('$Model$ $Parameters$', fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of notebook ----- Reference material ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "list_indices = [9,10,11,18,19,20,21]\n",
    "error_apical_one_d = np.zeros((14,1))\n",
    "error_basal_one_d = np.zeros((14,1))\n",
    "\n",
    "for i in range(7):\n",
    "    error_apical_one_d[2*i] = error_target_sampled_apical[2*list_indices[i]]\n",
    "    error_apical_one_d[2*i+1] = error_target_sampled_apical[2*list_indices[i] + 1]\n",
    "    error_basal_one_d[2*i] = error_target_sampled_basal[2*list_indices[i]]\n",
    "    error_basal_one_d[2*i+1] = error_target_sampled_basal[2*list_indices[i] + 1]\n",
    "\n",
    "np.save('error_apical_one_d.npy', error_apical_one_d)\n",
    "np.save('error_basal_one_d.npy', error_basal_one_d)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Defining the number of parameters and number of features in the study\n",
    "num_param = 22\n",
    "num_feature = 16\n",
    "\n",
    "# Initializing matrices for storing trace and determinants of the hessian\n",
    "fim_trace = np.zeros((num_feature,1))\n",
    "fim_det = np.zeros((num_feature,1))\n",
    "# Storing real and complex part of eigenvalues to ensure correctness in eigenvalue calculations\n",
    "fim_eig_real = np.zeros((num_feature,num_param))\n",
    "fim_eig_complex = np.zeros((num_feature,num_param))\n",
    "\n",
    "# Defining properties of figures \n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8), sharey=True, dpi=600)\n",
    "# Initializing counter\n",
    "k = 0\n",
    "\n",
    "# Loop over all  the jacobians of inmdividual features\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        # Fetching jacobian of individual features from the master sensitivity matrix\n",
    "        jacobian_feature = np.reshape(sens_master[:,k],(22,1))\n",
    "        # calculate fischer information matrix\n",
    "        # Note: Scaling wrt variance of jacobian has been done\n",
    "        fim_feature = np.matmul(jacobian_feature,jacobian_feature.transpose())/((np.std(jacobian_feature))**2)\n",
    "        # Calculate eigenvalue and eigenvectors of the symmetric matrix using eigh\n",
    "        fim_eigvalue, fim_eigenvector = np.linalg.eigh(fim_feature)\n",
    "        # Calculate trace\n",
    "        fim_trace[k] = np.trace(fim_feature)\n",
    "        # Calculate determinant\n",
    "        fim_det[k] = np.linalg.det(fim_feature)\n",
    "        # Calculating the real part of eigenvalue\n",
    "        fim_eig_real[k,:] = np.reshape((np.real(fim_eigvalue)),(1,22))\n",
    "        # Calculating the complex part of the eigenvalue\n",
    "        fim_eig_complex[k,:] = np.reshape((np.imag(fim_eigvalue)),(1,22))\n",
    "        \n",
    "        # Plotting FIMs as heatmaps using seaborn\n",
    "        hmap = sns.heatmap(fim_eigenvector, xticklabels = params_lhs, yticklabels = params_lhs, linewidths=.02, cmap=\"YlGnBu\",ax=axes[i,j])\n",
    "        # Setting up the plot titles as the features for which FIM has been calculated\n",
    "        axes[i,j].set_title(x_label[k])\n",
    "        # Adding colorbar\n",
    "        cbar = hmap.collections[0].colorbar\n",
    "        # Setting up the labelsizes\n",
    "        cbar.ax.tick_params(labelsize=5)\n",
    "        # Setting up fornts for xtick and yticklabels\n",
    "        hmap.set_xticklabels(hmap.get_xmajorticklabels(), fontsize = 3)\n",
    "        hmap.set_yticklabels(hmap.get_ymajorticklabels(), fontsize = 3)\n",
    "        # Increasing the counter. Moving to th enxt feature\n",
    "        k = k + 1\n",
    "\n",
    "# Increasing spacing between the subplots \n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "plt.subplots_adjust(wspace=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
